{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Contextualizing Transcriptomic Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/python\n",
    "\n",
    "# Dependencies\n",
    "import copy\n",
    "import time\n",
    "import numpy\n",
    "import cobra\n",
    "import pandas\n",
    "import bisect\n",
    "import symengine\n",
    "from cobra.util import solver\n",
    "from optlang.symbolics import Zero\n",
    "from cobra.manipulation.delete import remove_genes\n",
    "from cobra.flux_analysis.sampling import ACHRSampler\n",
    "from cobra.flux_analysis import flux_variability_analysis\n",
    "\n",
    "# Read in transcriptomic read abundances, default is tsv with no header \n",
    "def read_transcription_file(read_abundances_file, header=False, replicates=False, sep='\\t'):\n",
    "    '''Generates dictionary of transcriptomic abundances from a file.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    read_abundances_file : string\n",
    "        User-provided file name which contains gene IDs and associated transcription values\n",
    "    header : boolean\n",
    "        Defines if read abundance file has a header that needs to be ignored\n",
    "        default is no header\n",
    "    replicates : boolean\n",
    "        Defines if read abundances contains replicates and medians require calculation\n",
    "        default is no replicates\n",
    "    sep: string\n",
    "        Defines what character separates entries on each line\n",
    "        defaults to tab (.tsv)\n",
    "    '''\n",
    "    abund_dict = {}\n",
    "    with open(read_abundances_file, 'r') as transcription:\n",
    "        if header == True: header_line = transcription.readline()\n",
    "\n",
    "        for line in transcription:\n",
    "            line = line.split(sep)\n",
    "            gene = str(line[0])\n",
    "            \n",
    "            if replicates == True:\n",
    "                abundance = float(numpy.median([float(x) for x in line[1:]]))\n",
    "            else:\n",
    "                abundance = float(line[1])\n",
    "            \n",
    "            if gene in abund_dict.keys():\n",
    "                abund_dict[gene] += abundance\n",
    "            else:\n",
    "                abund_dict[gene] = abundance\n",
    "\n",
    "    return abund_dict\n",
    "\n",
    "        \n",
    "# Ensure that the user provided model and transcriptomic data are ready for RIPTiDe\n",
    "def initialize_model(model):\n",
    "    \n",
    "    # Create a copy of the original model and set new id\n",
    "    riptide_model = copy.deepcopy(model)\n",
    "    riptide_model.id = str(riptide_model.id) + '_riptide'\n",
    "    \n",
    "    # Check that the model can grow\n",
    "    solution = riptide_model.optimize()\n",
    "    if solution.objective_value < 1e-6 or str(solution.objective_value) == 'nan':\n",
    "        raise ValueError('ERROR: Provided model objective cannot carry flux! Please correct')\n",
    "    \n",
    "    # Calculate flux ranges and remove totally blocked reactions\n",
    "    flux_span = flux_variability_analysis(riptide_model, fraction_of_optimum=0.01)\n",
    "    flux_ranges = {}\n",
    "    blocked_rxns = []\n",
    "    for rxn_id, min_max in flux_span.iterrows():\n",
    "        if max(abs(min_max)) < 1e-6:\n",
    "            blocked_rxns.append(rxn_id)\n",
    "        else:\n",
    "            flux_ranges[rxn_id] = [min(min_max), max(min_max)]\n",
    "    for rxn in blocked_rxns: \n",
    "        riptide_model.reactions.get_by_id(rxn).remove_from_model(remove_orphans=True)\n",
    "\n",
    "    return riptide_model\n",
    "\n",
    "\n",
    "# Converts a dictionary of transcript distribution percentiles\n",
    "def assign_coefficients(raw_transcription_dict, model, percentiles, min_coefficients):\n",
    "    \n",
    "    # Screen transcriptomic abundances for genes that are included in model\n",
    "    transcription_dict = {}\n",
    "    for gene in model.genes:\n",
    "        try:\n",
    "            transcription_dict[gene.id] = raw_transcription_dict[gene.id]\n",
    "        except KeyError:\n",
    "            continue\n",
    "    \n",
    "    # Calculate transcript abundance cutoffs\n",
    "    distribution = transcription_dict.values()\n",
    "    abund_cutoffs = [numpy.percentile(distribution, x) for x in percentiles]\n",
    "    \n",
    "    # Screen transcript distribution by newly defined abundance intervals\n",
    "    coefficient_dict = {}\n",
    "    for gene in transcription_dict.iterkeys():\n",
    "        transcription = transcription_dict[gene]\n",
    "        if transcription in abund_cutoffs:\n",
    "            index = abund_cutoffs.index(transcription)\n",
    "            min_coefficient = min_coefficients[index]\n",
    "        else:\n",
    "            index = bisect.bisect_right(abund_cutoffs, transcription) - 1\n",
    "            min_coefficient = min_coefficients[index]\n",
    "                    \n",
    "        # Assign corresponding coefficients to reactions associated with each gene\n",
    "        for rxn in list(model.genes.get_by_any(gene)[0].reactions):            \n",
    "            if rxn.id in coefficient_dict.keys():\n",
    "                coefficient_dict[rxn.id].append(min_coefficient)\n",
    "            else:\n",
    "                coefficient_dict[rxn.id] = [min_coefficient]\n",
    "    \n",
    "    # Assign final coefficients\n",
    "    nogene_coefficient = numpy.median(min_coefficients)\n",
    "    for rxn in model.reactions:\n",
    "        try:\n",
    "            # Take smallest value for reactions assigned multiple coefficients\n",
    "            coefficient_dict[rxn.id] = min(coefficient_dict[rxn.id])\n",
    "        except KeyError:\n",
    "            coefficient_dict[rxn.id] = nogene_coefficient\n",
    "            continue\n",
    "    \n",
    "    return coefficient_dict\n",
    "\n",
    "\n",
    "# Read in user defined reactions to keep or exclude\n",
    "def incorporate_user_defined_reactions(rm_rxns, reaction_file):\n",
    "    \n",
    "    print('Integrating user definitions...')\n",
    "    sep = ',' if '.csv' in str(reaction_file) else '\\t'\n",
    "    \n",
    "    # Check if file actually exists    \n",
    "    try:\n",
    "        with open(reaction_file, 'r') as reactions:\n",
    "            include_rxns = set(reactions.readline().split(sep))\n",
    "            exclude_rxns = set(reactions.readline().split(sep))\n",
    "    except FileNotFoundError:\n",
    "        raise FileNotFoundError('ERROR: Defined reactions file not found! Please correct.')\n",
    "        \n",
    "    rm_rxns = rm_rxns.difference(include_rxns)\n",
    "    rm_rxns |= exclude_rxns\n",
    "\n",
    "    return rm_rxns\n",
    "\n",
    "\n",
    "# Determine those reactions that carry flux in a pFBA objective set to a threshold of maximum\n",
    "def constrain_and_analyze_model(model, coefficient_dict, fraction, sampling_depth):\n",
    "    \n",
    "    with model as constrained_model:\n",
    "\n",
    "        # Apply weigths to new expression\n",
    "        pfba_expr = Zero\n",
    "        if sampling_depth == 'minimization':\n",
    "            for rxn in constrained_model.reactions:\n",
    "                pfba_expr += coefficient_dict[rxn.id] * rxn.forward_variable\n",
    "                pfba_expr += coefficient_dict[rxn.id] * rxn.reverse_variable\n",
    "        else:\n",
    "            coeff_range = float(max(coefficient_dict.values())) + float(min(coefficient_dict.values()))\n",
    "            for rxn in constrained_model.reactions:\n",
    "                max_coeff = coeff_range - float(coefficient_dict[rxn.id])\n",
    "                pfba_expr += max_coeff * rxn.forward_variable\n",
    "                pfba_expr += max_coeff * rxn.reverse_variable\n",
    "                \n",
    "        # Calculate sum of fluxes constraint\n",
    "        if sampling_depth == 'minimization':\n",
    "            prev_obj_val = constrained_model.slim_optimize()\n",
    "            # Set previous objective as a constraint, allow deviation\n",
    "            prev_obj_constraint = constrained_model.problem.Constraint(constrained_model.objective.expression, lb=prev_obj_val*fraction, ub=prev_obj_val)\n",
    "            constrained_model.add_cons_vars([prev_obj_constraint])\n",
    "            constrained_model.objective = constrained_model.problem.Objective(pfba_expr, direction='min', sloppy=True)\n",
    "            constrained_model.solver.update()\n",
    "            solution = constrained_model.optimize()\n",
    "            \n",
    "            # Determine reactions that do not carry any flux in the constrained model\n",
    "            inactive_rxns = set([rxn.id for rxn in constrained_model.reactions if abs(solution.fluxes[rxn.id]) < 1e-6])\n",
    "            return inactive_rxns\n",
    "        \n",
    "        else:        \n",
    "            # Explore solution space of constrained model with flux sampling, allow deviation\n",
    "            constrained_model.objective = constrained_model.problem.Objective(pfba_expr, direction='max', sloppy=True)\n",
    "            solution = constrained_model.optimize()\n",
    "            flux_sum_obj_val = solution.objective_value\n",
    "            flux_sum_constraint = constrained_model.problem.Constraint(pfba_expr, lb=flux_sum_obj_val*fraction, ub=flux_sum_obj_val)\n",
    "            constrained_model.add_cons_vars([flux_sum_constraint])\n",
    "            constrained_model.solver.update()\n",
    "            \n",
    "            # Perform flux sampling (or FVA)\n",
    "            flux_object = explore_flux_ranges(constrained_model, sampling_depth, fraction)\n",
    "            return flux_object\n",
    "    \n",
    "\n",
    "# Prune model based on blocked reactions from minimization as well as user-defined reactions\n",
    "def prune_model(new_model, rm_rxns, defined_rxns, conserve):\n",
    "      \n",
    "    # Integrate user definitions\n",
    "    if defined_rxns != False: \n",
    "        rm_rxns = incorporate_user_defined_reactions(rm_rxns, defined_rxns)\n",
    "        \n",
    "    # Parse elements highlighted for pruning based on GPRs\n",
    "    if conserve == 'y':\n",
    "        final_rm_rxns = []\n",
    "        for rxn in rm_rxns:\n",
    "            test = 'pass'\n",
    "            current_genes = list(new_model.reactions.get_by_id(rxn).genes)\n",
    "            for gene in current_genes:\n",
    "                for rxn_sub in gene.reactions:\n",
    "                    if rxn_sub.id not in rm_rxns:\n",
    "                        test = 'fail'\n",
    "                    else:\n",
    "                        pass\n",
    "            \n",
    "        \tif test == 'pass': final_rm_rxns.append(rxn)\n",
    "    else:\n",
    "    \tfinal_rm_rxns = rm_rxns\n",
    "                        \n",
    "    # Screen for duplicates\n",
    "    final_rm_rxns = list(set(final_rm_rxns))\n",
    "    \n",
    "    # Prune inactive reactions\n",
    "    for rxn in final_rm_rxns:\n",
    "        new_model.reactions.get_by_id(rxn).remove_from_model(remove_orphans=True)\n",
    "    \n",
    "    # Prune possible residual orphans, kind of sloppy but it's the only way \n",
    "    # I've found for it to actually thoroughly remove orphans\n",
    "    removed = 1\n",
    "    while removed == 1:\n",
    "        removed = 0\n",
    "        for cpd in new_model.metabolites:\n",
    "            if len(cpd.reactions) == 0:\n",
    "                cpd.remove_from_model(remove_orphans=True); removed = 1\n",
    "        for rxn in new_model.reactions:\n",
    "            if len(rxn.metabolites) == 0: \n",
    "                rxn.remove_from_model(remove_orphans=True); removed = 1\n",
    "    \n",
    "    return new_model\n",
    "\n",
    "\n",
    "# Analyze the possible ranges of flux in the constrained model\n",
    "def explore_flux_ranges(model, samples, fraction):\n",
    "    \n",
    "    try:\n",
    "        sampling_object = ACHRSampler(model)\n",
    "        flux_object = sampling_object.sample(samples)        \n",
    "        analysis = 'flux_sampling'\n",
    "    except:\n",
    "        # Handle errors for models that are now too small\n",
    "        print('Constrained solution space too narrow for sampling, performing FVA instead')        \n",
    "        flux_object = flux_variability_analysis(model, fraction_of_optimum=fraction)\n",
    "        analysis = 'fva'\n",
    "        \n",
    "    return flux_object, analysis\n",
    "    \n",
    "    \n",
    "# Calculate approximate volume of solution space, treated as ellipsoid\n",
    "def calculate_polytope_volume(model, fraction):\n",
    "    \n",
    "    flux_span = flux_variability_analysis(model, fraction_of_optimum=fraction)\n",
    "    bounds = {}\n",
    "    for rxn_id, min_max in flux_span.iterrows(): bounds[rxn_id] = [min(min_max), max(min_max)]\n",
    "\n",
    "    # Compile a list of radii from flux ranges\n",
    "    radii = []\n",
    "    for rxn in bounds.iterkeys():\n",
    "        if bounds[rxn] == [0.0, 0.0]:\n",
    "            continue\n",
    "        else:\n",
    "            diameter = abs(bounds[rxn][0]) + abs(bounds[rxn][1])\n",
    "            radii.append(numpy.median(diameter) / 2.0)\n",
    "    \n",
    "    # Calculate volume \n",
    "    volume = (4.0/3.0) * numpy.pi * max(radii) * numpy.median(radii) * min(radii)\n",
    "    volume = round(volume, 3)\n",
    "    \n",
    "    return volume\n",
    "\n",
    "\n",
    "# Reports how long RIPTiDe took to run\n",
    "def operation_report(start_time, model, riptide, old_vol, new_vol):\n",
    "    \n",
    "    # Pruning\n",
    "    perc_removal = 100.0 - ((float(len(riptide.reactions)) / float(len(model.reactions))) * 100.0)\n",
    "    perc_removal = round(perc_removal, 1)\n",
    "    print('\\nReactions pruned to ' + str(len(riptide.reactions)) + ' from ' + str(len(model.reactions)) + ' (' + str(perc_removal) + '% reduction)')\n",
    "    perc_removal = 100.0 - ((float(len(riptide.metabolites)) / float(len(model.metabolites))) * 100.0)\n",
    "    perc_removal = round(perc_removal, 1)\n",
    "    print('Metabolites pruned to ' + str(len(riptide.metabolites)) + ' from ' + str(len(model.metabolites)) + ' (' + str(perc_removal) + '% reduction)')\n",
    "    \n",
    "    # Flux through objective\n",
    "    new_ov = round(riptide.slim_optimize(), 3)\n",
    "    old_ov = round(model.slim_optimize(), 3)\n",
    "    per_shift = 100.0 - ((new_ov / old_ov) * 100.0)\n",
    "    if per_shift == 0.0:\n",
    "        pass\n",
    "    elif per_shift > 0.0:\n",
    "        per_shift = round(abs(per_shift), 2)\n",
    "        print('\\nFlux through the objective REDUCED to ' + str(new_ov) + ' from ' + str(old_ov) + ' (' + str(per_shift) + '% shift)')\n",
    "    elif per_shift < 0.0:\n",
    "        per_shift = round(abs(per_shift), 2)\n",
    "        print('\\nFlux through the objective INCREASED to ' + str(new_ov) + ' from ' + str(old_ov) + ' (' + str(per_shift) + '% shift)')\n",
    "    \n",
    "    # Solution space volume\n",
    "    vol_shift = 100.0 - ((new_vol / old_vol) * 100.0)\n",
    "    if new_vol > 100000 or old_vol > 100000:\n",
    "        pass\n",
    "    elif vol_shift < 0.0:\n",
    "        vol_shift = round(abs(vol_shift), 2)\n",
    "        print('Solution space ellipsoid volume INCREASED to ~' + str(new_vol) + ' from ~' + str(old_vol) + ' (' + str(vol_shift) + '% shift)')\n",
    "    elif vol_shift > 0.0:\n",
    "        vol_shift = round(vol_shift, 2)\n",
    "        print('Solution space ellipsoid volume DECREASED to ~' + str(new_vol) + ' from ~' + str(old_vol) + ' (' + str(vol_shift) + '% shift)')\n",
    "    else:\n",
    "        print('No change in Solution space volume')\n",
    "    \n",
    "    # Check that prune model can still achieve flux through the objective (just in case)\n",
    "    if riptide.slim_optimize() < 1e-6 or str(riptide.slim_optimize()) == 'nan':\n",
    "        print('\\nWARNING: Contextualized model objective can no longer carry flux')\n",
    "    \n",
    "    # Run time\n",
    "    duration = time.time() - start_time\n",
    "    if duration < 60.0:\n",
    "        duration = round(duration)\n",
    "        print '\\nRIPTiDe completed in ' + str(duration) + ' seconds\\n'\n",
    "    elif duration < 3600.0:\n",
    "        duration = round((duration / 60.0), 1)\n",
    "        print '\\nRIPTiDe completed in ' + str(duration) + ' minutes\\n'\n",
    "    else:\n",
    "        duration = round((duration / 3600.0), 1)\n",
    "        print '\\nRIPTiDe completed in ' + str(duration) + ' hours\\n'\n",
    "\n",
    "\n",
    "# Create context-specific model based on transcript distribution\n",
    "def riptide(model, transcription, defined = False, sampling = 10000, percentiles = [50.0, 62.5, 75.0, 87.5], coefficients = [1.0, 0.5, 0.1, 0.01, 0.001], fraction = 0.8, conservative = 'n'):\n",
    "    '''Reaction Inclusion by Parsimony and Transcriptomic Distribution or RIPTiDe\n",
    "    \n",
    "    Creates a contextualized metabolic model based on parsimonious usage of reactions defined\n",
    "    by their associated transcriptomic abundances. Returns a pruned, context-specific cobra.Model \n",
    "    and a pandas.DataFrame of associated flux sampling distributions\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    model : cobra.Model\n",
    "        The model to be contextualized\n",
    "    transcription : dictionary\n",
    "        Dictionary of transcript abundances, output of read_transcription_file()\n",
    "    defined : False or File\n",
    "        Text file containing reactions IDs for forced inclusion listed on the first line and exclusion \n",
    "        listed on the second line (both .csv and .tsv formats supported)\n",
    "    sampling : int or False\n",
    "        Number of flux samples to collect, default is 10000, If False, sampling skipped\n",
    "    percentiles : list of floats\n",
    "        Percentile cutoffs of transcript abundance for linear coefficient assignments to associated reactions\n",
    "        Default is [50.0, 62.5, 75.0, 87.5]\n",
    "    coefficients : list of floats\n",
    "        Linear coefficients to weight reactions based on distribution placement\n",
    "        Default is [1.0, 0.5, 0.1, 0.01, 0.001]\n",
    "    fraction : float\n",
    "        Minimum percent of optimal objective value during FBA steps\n",
    "        Default is 0.8\n",
    "    conservative : str\n",
    "        Conservatively remove inactive reactions based on genes\n",
    "        Either 'y' or 'n', default in 'n' (no)\n",
    "    '''\n",
    "\n",
    "    start_time = time.time()\n",
    "    \n",
    "    # Correct some possible user error\n",
    "    if sampling == False:\n",
    "        pass\n",
    "    elif sampling <= 0: \n",
    "        sampling = 10000\n",
    "    else: \n",
    "        samples = int(sampling)\n",
    "    if len(set(transcription.values())) == 1:\n",
    "        raise ValueError('ERROR: All transcriptomic abundances are identical! Please correct')\n",
    "    if len(coefficients) != len(percentiles) + 1:\n",
    "        raise ValueError('ERROR: Invalid ratio of percentile cutoffs to linear coefficients! Please correct')\n",
    "    fraction = float(fraction)\n",
    "    if fraction <= 0.0:\n",
    "        fraction = 0.8\n",
    "    percentiles.sort() # sort ascending\n",
    "    coefficients.sort(reverse=True) # sort descending\n",
    "    if conservative not in ['y','n']: conservative = 'y'\n",
    "\n",
    "    # Check original model functionality\n",
    "    # Partition reactions based on transcription percentile intervals, assign corresponding reaction coefficients\n",
    "    print('\\nInitializing model and parsing transcriptome...')\n",
    "    riptide_model = initialize_model(model)\n",
    "    orig_volume = calculate_polytope_volume(riptide_model, fraction)\n",
    "    coefficient_dict = assign_coefficients(transcription, riptide_model, percentiles, coefficients)\n",
    "    \n",
    "    # Prune now inactive network sections based on coefficients\n",
    "    print('Pruning zero flux subnetworks...')\n",
    "    rm_rxns = constrain_and_analyze_model(riptide_model, coefficient_dict, fraction, 'minimization')\n",
    "    riptide_model = prune_model(riptide_model, rm_rxns, defined, conservative)\n",
    "    new_volume = calculate_polytope_volume(riptide_model, fraction)\n",
    "\n",
    "    # Find optimal solution space based on transcription and final constraints\n",
    "    if sampling != False:\n",
    "        print('Sampling context-specific solution space (longest step)...')\n",
    "        flux_object, analysis_type = constrain_and_analyze_model(riptide_model, coefficient_dict, fraction, samples)\n",
    "        operation_report(start_time, model, riptide_model, orig_volume, new_volume)\n",
    "        return riptide_model, flux_object\n",
    "    \n",
    "    else:\n",
    "        operation_report(start_time, model, riptide_model, orig_volume, new_volume)\n",
    "        return riptide_model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing with Toy Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy\n",
    "import pandas\n",
    "import operator\n",
    "from cobra.flux_analysis.parsimonious import *\n",
    "\n",
    "# Use FBA calculations to find new shadow prices\n",
    "def shadow_prices(model, compartment='all', top=25):\n",
    "    with model as m: solution = pfba(m)\n",
    "    \n",
    "    shadow_prices = {}\n",
    "    for cpd, price in solution.shadow_prices.iteritems():\n",
    "        cpd = model.metabolites.get_by_any(cpd)[0]\n",
    "        if compartment != 'all' and compartment != cpd.compartment:\n",
    "            continue\n",
    "        else:\n",
    "            if price > 0.0: shadow_prices[cpd.name] = price\n",
    "\n",
    "    sorted_prices = sorted(shadow_prices.items(), key=operator.itemgetter(1), reverse=True)[0:top]\n",
    "    sorted_prices = pandas.DataFrame(sorted_prices, columns=['metabolite', 'shadow_price'])\n",
    "    \n",
    "    return sorted_prices\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load in example model\n",
    "toy_model = cobra.io.read_sbml_model('/home/mjenior/Desktop/repos/Jenior_RIPTiDe_2019/data/example_GENRE.sbml')\n",
    "\n",
    "# gene1 = Glucose transporter\n",
    "# gene2 = Proline transporter\n",
    "# gene3 = Glycine transporter\n",
    "# gene4 = Hydrogen efflux\n",
    "# gene5 = Carbon dioxide efflux\n",
    "# gene6 = Phosphate transporter\n",
    "# gene7 = Glycolysis\n",
    "# gene8 = Stickland fermentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <table>\n",
       "            <tr>\n",
       "                <td><strong>Name</strong></td>\n",
       "                <td>iTEST</td>\n",
       "            </tr><tr>\n",
       "                <td><strong>Memory address</strong></td>\n",
       "                <td>0x07f53912035d0</td>\n",
       "            </tr><tr>\n",
       "                <td><strong>Number of metabolites</strong></td>\n",
       "                <td>14</td>\n",
       "            </tr><tr>\n",
       "                <td><strong>Number of reactions</strong></td>\n",
       "                <td>16</td>\n",
       "            </tr><tr>\n",
       "                <td><strong>Objective expression</strong></td>\n",
       "                <td>0.0 + 1.0*DM_atp_c - 1.0*DM_atp_c_reverse_1b037</td>\n",
       "            </tr><tr>\n",
       "                <td><strong>Compartments</strong></td>\n",
       "                <td>c, e</td>\n",
       "            </tr>\n",
       "          </table>"
      ],
      "text/plain": [
       "<Model iTEST at 0x7f53912035d0>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "toy_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>metabolite</th>\n",
       "      <th>shadow_price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ATP</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CO2</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Glycine</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Pi</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Proline</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Glucose</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>ADP</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  metabolite  shadow_price\n",
       "0        ATP           8.0\n",
       "1        CO2           2.0\n",
       "2    Glycine           2.0\n",
       "3         Pi           2.0\n",
       "4    Proline           2.0\n",
       "5    Glucose           2.0\n",
       "6        ADP           1.0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shadow_prices(toy_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EX_gluc_e   -1000.0\n",
      "rxn1         1000.0\n",
      "EX_pro_e        0.0\n",
      "rxn2            0.0\n",
      "EX_gly_e        0.0\n",
      "rxn3            0.0\n",
      "EX_h_e       1000.0\n",
      "rxn4         1000.0\n",
      "EX_co2_e        0.0\n",
      "rxn5            0.0\n",
      "EX_pi_e     -1000.0\n",
      "rxn6         1000.0\n",
      "EX_adp_c    -1000.0\n",
      "rxn7         1000.0\n",
      "rxn8            0.0\n",
      "DM_atp_c     1000.0\n",
      "Name: fluxes, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Find most parsimonious route of flux\n",
    "from cobra.flux_analysis.parsimonious import pfba\n",
    "toy_solution = pfba(toy_model)\n",
    "print(toy_solution.fluxes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create associated transcriptomes\n",
    "glucose_transcriptome = {'gene1':100, 'gene2':1, 'gene3':1, 'gene4':1, \n",
    "                         'gene5':1, 'gene6':100, 'gene7':10000, 'gene8':1}\n",
    "peptide_transcriptome = {'gene1':1, 'gene2':100, 'gene3':100, 'gene4':1, \n",
    "                         'gene5':1, 'gene6':1, 'gene7':1, 'gene8':10000}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Initializing model and parsing transcriptome...\n",
      "Pruning zero flux subnetworks...\n",
      "\n",
      "Reactions pruned to 9 from 16 (43.8% reduction)\n",
      "Metabolites pruned to 8 from 14 (42.9% reduction)\n",
      "\n",
      "RIPTiDe completed in 1.0 seconds\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Contextualize toy model\n",
    "toy_model_glucose, glucose_samples = riptide(toy_model, glucose_transcriptome)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>metabolite</th>\n",
       "      <th>shadow_price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ATP</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Pi</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Glucose</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ADP</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  metabolite  shadow_price\n",
       "0        ATP           8.0\n",
       "1         Pi           2.0\n",
       "2    Glucose           2.0\n",
       "3        ADP           1.0"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shadow_prices(toy_model_glucose)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Initializing model and parsing transcriptome...\n",
      "Pruning zero flux subnetworks...\n",
      "Sampling context-specific solution space (longest step)...\n",
      "\n",
      "Reactions pruned to 13 from 16 (18.8% reduction)\n",
      "Metabolites pruned to 12 from 14 (14.3% reduction)\n",
      "\n",
      "No change in flux through the objective\n",
      "\n",
      "RIPTiDe completed in 1.6 minutes\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Contextualize toy model\n",
    "toy_model_peptide, peptide_samples = riptide(toy_model, peptide_transcriptome)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>metabolite</th>\n",
       "      <th>shadow_price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ATP</td>\n",
       "      <td>12.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Pi</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Proline</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Glycine</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ADP</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  metabolite  shadow_price\n",
       "0        ATP          12.0\n",
       "1         Pi           2.0\n",
       "2    Proline           2.0\n",
       "3    Glycine           2.0\n",
       "4        ADP           1.0"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shadow_prices(toy_model_peptide)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "WilcoxonResult(statistic=11743036.0, pvalue=0.0)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test difference in objective fluxes\n",
    "gluc_arp = glucose_samples['DM_atp_c']\n",
    "pep_arp = peptide_samples['DM_atp_c']\n",
    "\n",
    "import scipy.stats\n",
    "scipy.stats.wilcoxon(x=gluc_arp, y=pep_arp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing with E.coli K-12 MG1655 model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "iJO1366 = cobra.io.read_sbml_model('/home/mjenior/Desktop/repos/Jenior_RIPTiDe_2019/data/iJO1366.xml')\n",
    "iJO1366.objective = iJO1366.reactions.BIOMASS_Ec_iJO1366_WT_53p95M\n",
    "\n",
    "# Open all exchanges\n",
    "exchanges = set()\n",
    "for rxn in iJO1366.reactions:\n",
    "    if len(rxn.reactants) == 0 or len(rxn.products) == 0:\n",
    "        rxn.bounds = (min(rxn.lower_bound, -1000), max(rxn.upper_bound, 1000))\n",
    "        exchanges |= set([rxn.id])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def max_doubling_time(model):\n",
    "    \n",
    "    with model as m: \n",
    "        growth =  m.slim_optimize()\n",
    "    \n",
    "    if growth < 1e-6:\n",
    "        growth = 'No growth'\n",
    "    else:    \n",
    "        growth = (1.0 / growth) * 3600.0\n",
    "        if growth < 60.0:\n",
    "            growth = str(round(growth, 1)) + ' minutes'\n",
    "        else:\n",
    "            growth = growth / 60.0\n",
    "            growth = str(round(growth, 3)) + ' hours'\n",
    "            \n",
    "    print(growth)\n",
    "\n",
    "\n",
    "def collect_doubling_times(flux_samples, biomass):\n",
    "    biomass = list(flux_samples[biomass])\n",
    "    times = []\n",
    "    \n",
    "    for x in biomass:\n",
    "        growth = (1.0 / x) * 3600.0 # Calculated in minutes\n",
    "        growth = round(growth, 2)\n",
    "        times.append(growth)\n",
    "        \n",
    "    return times\n",
    "\n",
    "\n",
    "def collect_growth_rates(flux_samples, biomass):\n",
    "    biomass = list(flux_samples[biomass])\n",
    "    rates = []\n",
    "    \n",
    "    for x in biomass:\n",
    "        rate = x / 60.0\n",
    "        rate = round(rate, 3)\n",
    "        rates.append(rate)\n",
    "        \n",
    "    return rates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34.0 minutes\n"
     ]
    }
   ],
   "source": [
    "max_doubling_time(iJO1366)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <table>\n",
       "            <tr>\n",
       "                <td><strong>Name</strong></td>\n",
       "                <td>iJO1366</td>\n",
       "            </tr><tr>\n",
       "                <td><strong>Memory address</strong></td>\n",
       "                <td>0x07f8f897aa3d0</td>\n",
       "            </tr><tr>\n",
       "                <td><strong>Number of metabolites</strong></td>\n",
       "                <td>1805</td>\n",
       "            </tr><tr>\n",
       "                <td><strong>Number of reactions</strong></td>\n",
       "                <td>2583</td>\n",
       "            </tr><tr>\n",
       "                <td><strong>Objective expression</strong></td>\n",
       "                <td>0.0 + 1.0*BIOMASS_Ec_iJO1366_WT_53p95M - 1.0*BIOMASS_Ec_iJO1366_WT_53p95M_reverse_06c4a</td>\n",
       "            </tr><tr>\n",
       "                <td><strong>Compartments</strong></td>\n",
       "                <td>periplasm, cytosol, extracellular space</td>\n",
       "            </tr>\n",
       "          </table>"
      ],
      "text/plain": [
       "<Model iJO1366 at 0x7f8f897aa3d0>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iJO1366"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Flux sampling on base model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prune blocked reactions\n",
    "flux_span = flux_variability_analysis(iJO1366, fraction_of_optimum=0.01)\n",
    "blocked_rxns = []\n",
    "for rxn_id, min_max in flux_span.iterrows():\n",
    "    if max(abs(min_max)) < 1e-6: blocked_rxns.append(rxn_id)\n",
    "for rxn in blocked_rxns: \n",
    "    iJO1366.reactions.get_by_id(rxn).remove_from_model(remove_orphans=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constrain possible solutions\n",
    "obj_val = iJO1366.slim_optimize()\n",
    "obj_constraint = iJO1366.problem.Constraint(iJO1366.objective.expression, lb=obj_val*0.8, ub=obj_val)\n",
    "iJO1366.add_cons_vars([obj_constraint])\n",
    "iJO1366.solver.update()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-69727.61, 92.4, 665273.68]\n"
     ]
    }
   ],
   "source": [
    "# Flux sampling of base model\n",
    "iJO1366_sampling_object = ACHRSampler(iJO1366)\n",
    "iJO1366_flux_samples = iJO1366_sampling_object.sample(5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Collect base model growth information\n",
    "base_rates = collect_growth_rates(iJO1366_flux_samples, 'BIOMASS_Ec_iJO1366_WT_53p95M')\n",
    "\n",
    "# Screen data against negative values\n",
    "screened_base_rates = []\n",
    "for x in base_rates:\n",
    "    if x > 0.0: \n",
    "        screened_base_rates.append(str(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save times to a file\n",
    "with open('/home/mjenior/Desktop/repos/Jenior_RIPTiDe_2019/data/unconstrained_growth_rates.tsv', 'w') as rates:\n",
    "    for x in screened_base_rates: rates.write(x + '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Contextualizing Published Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in transcriptomes\n",
    "\n",
    "# Data collected from:\n",
    "# Monk et al. (2016). Multi-omics Quantification of Species Variation of Escherichia coli\n",
    "# Links Molecular Features with Strain Phenotypes. Cell Systems. 3; 238–251.\n",
    "\n",
    "# Load in GPR translations\n",
    "gpr_dict = {}\n",
    "with open('/home/mjenior/Desktop/repos/Jenior_RIPTiDe_2019/data/Monk_et_al_2016/iJO1366_genes.tsv', 'r') as genes:\n",
    "    for line in genes:\n",
    "        line = line.split()\n",
    "        gpr_dict[line[1]] = line[0]\n",
    "\n",
    "# Normalized abundances\n",
    "# Separate into treatment goups and calculate medians\n",
    "m9_aerobic = {}\n",
    "m9_anaerobic = {}     \n",
    "with open('/home/mjenior/Desktop/repos/Jenior_RIPTiDe_2019/data/Monk_et_al_2016/normalized.tsv', 'r') as transcription:\n",
    "    for line in transcription:\n",
    "        line = line.split()\n",
    "        if line[0] == 'gene':\n",
    "            continue\n",
    "        else:\n",
    "            try:\n",
    "                gene = gpr_dict[line[0]]\n",
    "            except:\n",
    "                continue\n",
    "            m9_aerobic[gene] = numpy.median([int(x) for x in line[1:4]])\n",
    "            m9_anaerobic[gene] = numpy.median([int(y) for y in line[4:7]])\n",
    "\n",
    "# Rich media (LB) data from:\n",
    "# Double-stranded transcriptome of E. coli\n",
    "# Meghan Lybecker, Bob Zimmermann, Ivana Bilusic, Nadezda Tukhtubaeva, Renée Schroeder\n",
    "# Proceedings of the National Academy of Sciences Feb 2014, 111 (8) 3134-3139; DOI: 10.1073/pnas.1315974111\n",
    "lb_aerobic = {}     \n",
    "with open('/home/mjenior/Desktop/repos/Jenior_RIPTiDe_2019/data/Lybecker_2014.mapped.norm.tsv', 'r') as transcription:\n",
    "    header = transcription.readline()\n",
    "    for line in transcription: \n",
    "        line = line.split()\n",
    "        lb_aerobic[line[0]] = float(line[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing model and parsing transcriptome...\n",
      "Pruning zero flux subnetworks...\n",
      "Sampling context-specific solution space (longest step)...\n",
      "\n",
      "Reactions pruned to 467 from 2583 (81.9% reduction)\n",
      "Metabolites pruned to 466 from 1805 (74.2% reduction)\n",
      "\n",
      "Flux through the objective REDUCED to 60.203 from 105.765 (43.08% shift)\n",
      "Solution space ellipsoid volume DECREASED to ~0.262 from ~36.576 (99.28% shift)\n",
      "\n",
      "RIPTiDe completed in 4.2 minutes\n"
     ]
    }
   ],
   "source": [
    "# Aerobic growth in M9 + glucose\n",
    "iJO1366_m9_aerobic, m9_aerobic_samples = riptide(iJO1366, m9_aerobic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <table>\n",
       "            <tr>\n",
       "                <td><strong>Name</strong></td>\n",
       "                <td>iJO1366_riptide</td>\n",
       "            </tr><tr>\n",
       "                <td><strong>Memory address</strong></td>\n",
       "                <td>0x07f97fb6b0a90</td>\n",
       "            </tr><tr>\n",
       "                <td><strong>Number of metabolites</strong></td>\n",
       "                <td>466</td>\n",
       "            </tr><tr>\n",
       "                <td><strong>Number of reactions</strong></td>\n",
       "                <td>467</td>\n",
       "            </tr><tr>\n",
       "                <td><strong>Objective expression</strong></td>\n",
       "                <td>0.0 + 1.0*BIOMASS_Ec_iJO1366_WT_53p95M - 1.0*BIOMASS_Ec_iJO1366_WT_53p95M_reverse_06c4a</td>\n",
       "            </tr><tr>\n",
       "                <td><strong>Compartments</strong></td>\n",
       "                <td>periplasm, cytosol, extracellular space</td>\n",
       "            </tr>\n",
       "          </table>"
      ],
      "text/plain": [
       "<Model iJO1366_riptide at 0x7f97fb6b0a90>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iJO1366_m9_aerobic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "60.180610780793984"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iJO1366_m9_aerobic.slim_optimize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[65.36, 84.06, 86.4]\n",
      "[0.694, 0.714, 0.918]\n"
     ]
    }
   ],
   "source": [
    "m9_aerobic_times = collect_doubling_times(m9_aerobic_samples, 'BIOMASS_Ec_iJO1366_WT_53p95M')\n",
    "print([min(m9_aerobic_times), numpy.median(m9_aerobic_times), max(m9_aerobic_times)])\n",
    "m9_aerobic_rates = collect_growth_rates(m9_aerobic_samples, 'BIOMASS_Ec_iJO1366_WT_53p95M')\n",
    "print([min(m9_aerobic_rates), numpy.median(m9_aerobic_rates), max(m9_aerobic_rates)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run in aerobic exchange conditions\n",
    "#iJO1366_m9_anaerobic_test, m9_anaerobic_samples_test = riptide(iJO1366, m9_anaerobic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "#max_doubling_time(iJO1366_m9_anaerobic_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "#m9_aerobic_rates_test = collect_growth_rates(m9_anaerobic_samples_test, 'BIOMASS_Ec_iJO1366_WT_53p95M')\n",
    "#print([min(m9_aerobic_rates_test), numpy.median(m9_aerobic_rates_test), max(m9_aerobic_rates_test)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing model and parsing transcriptome...\n",
      "Pruning zero flux subnetworks...\n",
      "Sampling context-specific solution space (longest step)...\n",
      "\n",
      "Reactions pruned to 501 from 2583 (80.6% reduction)\n",
      "Metabolites pruned to 503 from 1805 (72.1% reduction)\n",
      "\n",
      "Flux through the objective REDUCED to 41.662 from 105.765 (60.61% shift)\n",
      "Solution space ellipsoid volume DECREASED to ~0.162 from ~36.576 (99.56% shift)\n",
      "\n",
      "RIPTiDe completed in 5.6 minutes\n"
     ]
    }
   ],
   "source": [
    "# Anaerobic growth in M9 + glucose\n",
    "#iJO1366.reactions.get_by_id('EX_o2_e').bounds = (0.0, 0.0) # make anaerobic\n",
    "iJO1366_m9_anaerobic, m9_anaerobic_samples = riptide(iJO1366, m9_anaerobic)\n",
    "#iJO1366.reactions.get_by_id('EX_o2_e').bounds = (-1000.0, 1000.0) # revert change"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <table>\n",
       "            <tr>\n",
       "                <td><strong>Name</strong></td>\n",
       "                <td>iJO1366_riptide</td>\n",
       "            </tr><tr>\n",
       "                <td><strong>Memory address</strong></td>\n",
       "                <td>0x07f97f5348710</td>\n",
       "            </tr><tr>\n",
       "                <td><strong>Number of metabolites</strong></td>\n",
       "                <td>503</td>\n",
       "            </tr><tr>\n",
       "                <td><strong>Number of reactions</strong></td>\n",
       "                <td>501</td>\n",
       "            </tr><tr>\n",
       "                <td><strong>Objective expression</strong></td>\n",
       "                <td>0.0 + 1.0*BIOMASS_Ec_iJO1366_WT_53p95M - 1.0*BIOMASS_Ec_iJO1366_WT_53p95M_reverse_06c4a</td>\n",
       "            </tr><tr>\n",
       "                <td><strong>Compartments</strong></td>\n",
       "                <td>periplasm, cytosol, extracellular space</td>\n",
       "            </tr>\n",
       "          </table>"
      ],
      "text/plain": [
       "<Model iJO1366_riptide at 0x7f97f5348710>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iJO1366_m9_anaerobic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_doubling_time(iJO1366_m9_anaerobic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[90.55, 280.415, 401.4]\n",
      "[0.149, 0.214, 0.663]\n"
     ]
    }
   ],
   "source": [
    "m9_anaerobic_times = collect_doubling_times(m9_anaerobic_samples, 'BIOMASS_Ec_iJO1366_WT_53p95M')\n",
    "print([min(m9_anaerobic_times), numpy.median(m9_anaerobic_times), max(m9_anaerobic_times)])\n",
    "m9_anaerobic_rates = collect_growth_rates(m9_anaerobic_samples, 'BIOMASS_Ec_iJO1366_WT_53p95M')\n",
    "print([min(m9_anaerobic_rates), numpy.median(m9_anaerobic_rates), max(m9_anaerobic_rates)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing model and parsing transcriptome...\n",
      "Pruning zero flux subnetworks...\n",
      "Sampling context-specific solution space (longest step)...\n",
      "\n",
      "Reactions pruned to 494 from 2583 (80.9% reduction)\n",
      "Metabolites pruned to 495 from 1805 (72.6% reduction)\n",
      "\n",
      "Flux through the objective REDUCED to 57.284 from 105.765 (45.84% shift)\n",
      "Solution space ellipsoid volume DECREASED to ~0.354 from ~36.576 (99.03% shift)\n",
      "\n",
      "RIPTiDe completed in 4.7 minutes\n"
     ]
    }
   ],
   "source": [
    "# Aerobic growth in LB\n",
    "iJO1366_lb_aerobic, lb_samples = riptide(iJO1366, lb_aerobic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <table>\n",
       "            <tr>\n",
       "                <td><strong>Name</strong></td>\n",
       "                <td>iJO1366_riptide</td>\n",
       "            </tr><tr>\n",
       "                <td><strong>Memory address</strong></td>\n",
       "                <td>0x07f97e5f95e90</td>\n",
       "            </tr><tr>\n",
       "                <td><strong>Number of metabolites</strong></td>\n",
       "                <td>495</td>\n",
       "            </tr><tr>\n",
       "                <td><strong>Number of reactions</strong></td>\n",
       "                <td>494</td>\n",
       "            </tr><tr>\n",
       "                <td><strong>Objective expression</strong></td>\n",
       "                <td>0.0 + 1.0*BIOMASS_Ec_iJO1366_WT_53p95M - 1.0*BIOMASS_Ec_iJO1366_WT_53p95M_reverse_06c4a</td>\n",
       "            </tr><tr>\n",
       "                <td><strong>Compartments</strong></td>\n",
       "                <td>periplasm, cytosol, extracellular space</td>\n",
       "            </tr>\n",
       "          </table>"
      ],
      "text/plain": [
       "<Model iJO1366_riptide at 0x7f97e5f95e90>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iJO1366_lb_aerobic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.44 hours\n"
     ]
    }
   ],
   "source": [
    "max_doubling_time(iJO1366_lb_aerobic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[130.42, 358.015, 493.16]\n",
      "[0.122, 0.168, 0.46]\n"
     ]
    }
   ],
   "source": [
    "lb_aerobic_times = collect_doubling_times(lb_samples, 'BIOMASS_Ec_iJO1366_WT_53p95M')\n",
    "print([min(lb_aerobic_times), numpy.median(lb_aerobic_times), max(lb_aerobic_times)])\n",
    "lb_aerobic_rates = collect_growth_rates(lb_samples, 'BIOMASS_Ec_iJO1366_WT_53p95M')\n",
    "print([min(lb_aerobic_rates), numpy.median(lb_aerobic_rates), max(lb_aerobic_rates)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing model and parsing transcriptome...\n",
      "Pruning zero flux subnetworks...\n",
      "Sampling context-specific solution space (longest step)...\n",
      "\n",
      "Reactions pruned to 449 from 2583 (82.6% reduction)\n",
      "Metabolites pruned to 449 from 1805 (75.1% reduction)\n",
      "\n",
      "Flux through the objective REDUCED to 56.29 from 105.765 (46.78% shift)\n",
      "Solution space ellipsoid volume DECREASED to ~0.302 from ~9.161 (96.7% shift)\n",
      "\n",
      "RIPTiDe completed in 3.8 minutes\n"
     ]
    }
   ],
   "source": [
    "# Compare to base implementation of pFBA\n",
    "# All coefficients set to 1.0, so transcriptome is irrelevant\n",
    "iJO1366_pfba, pfba_samples = riptide(iJO1366, m9_aerobic, coefficients=[1.0,1.0,1.0,1.0,1.0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <table>\n",
       "            <tr>\n",
       "                <td><strong>Name</strong></td>\n",
       "                <td>iJO1366_riptide</td>\n",
       "            </tr><tr>\n",
       "                <td><strong>Memory address</strong></td>\n",
       "                <td>0x07f7d70f15750</td>\n",
       "            </tr><tr>\n",
       "                <td><strong>Number of metabolites</strong></td>\n",
       "                <td>449</td>\n",
       "            </tr><tr>\n",
       "                <td><strong>Number of reactions</strong></td>\n",
       "                <td>449</td>\n",
       "            </tr><tr>\n",
       "                <td><strong>Objective expression</strong></td>\n",
       "                <td>0.0 + 1.0*BIOMASS_Ec_iJO1366_WT_53p95M - 1.0*BIOMASS_Ec_iJO1366_WT_53p95M_reverse_06c4a</td>\n",
       "            </tr><tr>\n",
       "                <td><strong>Compartments</strong></td>\n",
       "                <td>periplasm, cytosol, extracellular space</td>\n",
       "            </tr>\n",
       "          </table>"
      ],
      "text/plain": [
       "<Model iJO1366_riptide at 0x7f7d70f15750>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iJO1366_pfba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "57.20042650657536"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iJO1366_pfba.slim_optimize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "374"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(iJO1366_pfba.genes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.694, 0.716, 0.938]\n"
     ]
    }
   ],
   "source": [
    "pfba_rates = collect_growth_rates(pfba_samples, 'BIOMASS_Ec_iJO1366_WT_53p95M')\n",
    "print([min(pfba_rates), numpy.median(pfba_rates), max(pfba_rates)])\n",
    "with open('/home/mjenior/Desktop/repos/Jenior_RIPTiDe_2019/data/pfba_growth_rates.tsv', 'w') as output_file:\n",
    "    for x in pfba_rates: output_file.write(str(x) + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "write pfba_times to file\n",
    "with open('/home/mjenior/Desktop/repos/Jenior_RIPTiDe_2019/data/invivo_growth_rates.tsv', 'w') as output_file:\n",
    "    for x in pfba_times: output_file.write(str(x) + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compares lists to create diagrams for 4 groups\n",
    "def venn_comparison(list1, list2, list3, list4):\n",
    "        \n",
    "    # Confirm correct data types\n",
    "    list1 = set(list1)\n",
    "    list2 = set(list2)\n",
    "    list3 = set(list3)\n",
    "    list4 = set(list4)\n",
    "    \n",
    "    # Identify exclusive elements\n",
    "    list1_only = list1.difference(list2)\n",
    "    list1_only = list1_only.difference(list3)\n",
    "    list1_only = list1_only.difference(list4)\n",
    "    list2_only = list2.difference(list1)\n",
    "    list2_only = list2_only.difference(list3)\n",
    "    list2_only = list2_only.difference(list4)\n",
    "    list3_only = list3.difference(list1)\n",
    "    list3_only = list3_only.difference(list2)\n",
    "    list3_only = list3_only.difference(list4)\n",
    "    list4_only = list4.difference(list1)\n",
    "    list4_only = list4_only.difference(list2)\n",
    "    list4_only = list4_only.difference(list3)\n",
    "\n",
    "    # Find overlap between just 2 groups\n",
    "    list1_list2_overlap = list1.intersection(list2)\n",
    "    list1_list2_overlap = list1_list2_overlap.difference(list3)\n",
    "    list1_list2_overlap = list1_list2_overlap.difference(list4)\n",
    "    list1_list3_overlap = list1.intersection(list3)\n",
    "    list1_list3_overlap = list1_list3_overlap.difference(list2)\n",
    "    list1_list3_overlap = list1_list3_overlap.difference(list4)\n",
    "    list1_list4_overlap = list1.intersection(list4)\n",
    "    list1_list4_overlap = list1_list4_overlap.difference(list2)\n",
    "    list1_list4_overlap = list1_list4_overlap.difference(list3)\n",
    "    list2_list3_overlap = list2.intersection(list3)\n",
    "    list2_list3_overlap = list2_list3_overlap.difference(list1)\n",
    "    list2_list3_overlap = list2_list3_overlap.difference(list4)\n",
    "    list2_list4_overlap = list2.intersection(list4)\n",
    "    list2_list4_overlap = list2_list4_overlap.difference(list1)\n",
    "    list2_list4_overlap = list2_list4_overlap.difference(list3)\n",
    "    list3_list4_overlap = list3.intersection(list4)\n",
    "    list3_list4_overlap = list3_list4_overlap.difference(list1)\n",
    "    list3_list4_overlap = list3_list4_overlap.difference(list2)\n",
    "\n",
    "    # Find overlap in 3 groups\n",
    "    list1_list2_list3_overlap = list1.intersection(list2)\n",
    "    list1_list2_list3_overlap = list1_list2_list3_overlap.intersection(list3)\n",
    "    list1_list2_list3_overlap = list1_list2_list3_overlap.difference(list4)\n",
    "    list1_list2_list4_overlap = list1.intersection(list2)\n",
    "    list1_list2_list4_overlap = list1_list2_list4_overlap.intersection(list4)\n",
    "    list1_list2_list4_overlap = list1_list2_list4_overlap.difference(list3)\n",
    "    list1_list3_list4_overlap = list1.intersection(list3)\n",
    "    list1_list3_list4_overlap = list1_list3_list4_overlap.intersection(list4)\n",
    "    list1_list3_list4_overlap = list1_list3_list4_overlap.difference(list2)\n",
    "    list2_list3_list4_overlap = list2.intersection(list3)\n",
    "    list2_list3_list4_overlap = list2_list3_list4_overlap.intersection(list4)\n",
    "    list2_list3_list4_overlap = list2_list3_list4_overlap.difference(list1)\n",
    "    \n",
    "    # Find overlap between all groups\n",
    "    all_list_overlap = list1.intersection(list2)\n",
    "    all_list_overlap = all_list_overlap.intersection(list3)\n",
    "    all_list_overlap = all_list_overlap.intersection(list4)\n",
    "    \n",
    "    # Calculate totals in each group\n",
    "    list1_total = float(len(list1))\n",
    "    list2_total = float(len(list2))\n",
    "    list3_total = float(len(list3))\n",
    "    list4_total = float(len(list4))\n",
    "    list1_only_total = float(len(list1_only))\n",
    "    list2_only_total = float(len(list2_only))\n",
    "    list3_only_total = float(len(list3_only))\n",
    "    list4_only_total = float(len(list4_only))\n",
    "    list1_list2_overlap_total = float(len(list1_list2_overlap))\n",
    "    list1_list3_overlap_total = float(len(list1_list3_overlap))\n",
    "    list1_list4_overlap_total = float(len(list1_list4_overlap))\n",
    "    list2_list3_overlap_total = float(len(list2_list3_overlap))\n",
    "    list2_list4_overlap_total = float(len(list2_list4_overlap))\n",
    "    list3_list4_overlap_total = float(len(list3_list4_overlap))\n",
    "    list1_list2_list3_overlap_total = float(len(list1_list2_list3_overlap))\n",
    "    list1_list2_list4_overlap_total = float(len(list1_list2_list4_overlap))\n",
    "    list1_list3_list4_overlap_total = float(len(list1_list3_list4_overlap))\n",
    "    list2_list3_list4_overlap_total = float(len(list2_list3_list4_overlap))\n",
    "    all_list_overlap_total = float(len(all_list_overlap))\n",
    "    \n",
    "    # Calculate percent overlaps\n",
    "    list1_only_percent = round(((list1_only_total / list1_total) * 100.0), 1)\n",
    "    list2_only_percent = round(((list2_only_total / list2_total) * 100.0), 1)\n",
    "    list3_only_percent = round(((list3_only_total / list3_total) * 100.0), 1)\n",
    "    list4_only_percent = round(((list4_only_total / list4_total) * 100.0), 1)\n",
    "    temp1 = (list1_list2_overlap_total / list1_total) * 100.0\n",
    "    temp2 = (list1_list2_overlap_total / list2_total) * 100.0\n",
    "    list1_list2_overlap_percent = round(numpy.mean([temp1, temp2]), 1)\n",
    "    temp1 = (list1_list3_overlap_total / list1_total) * 100.0\n",
    "    temp2 = (list1_list3_overlap_total / list3_total) * 100.0\n",
    "    list1_list3_overlap_percent = round(numpy.mean([temp1, temp2]), 1)\n",
    "    temp1 = (list1_list4_overlap_total / list1_total) * 100.0\n",
    "    temp2 = (list1_list4_overlap_total / list4_total) * 100.0\n",
    "    list1_list4_overlap_percent = round(numpy.mean([temp1, temp2]), 1)\n",
    "    temp1 = (list2_list3_overlap_total / list2_total) * 100.0\n",
    "    temp2 = (list2_list3_overlap_total / list3_total) * 100.0\n",
    "    list2_list3_overlap_percent = round(numpy.mean([temp1, temp2]), 1)\n",
    "    temp1 = (list2_list4_overlap_total / list2_total) * 100.0\n",
    "    temp2 = (list2_list4_overlap_total / list4_total) * 100.0\n",
    "    list2_list4_overlap_percent = round(numpy.mean([temp1, temp2]), 1)\n",
    "    temp1 = (list3_list4_overlap_total / list3_total) * 100.0\n",
    "    temp2 = (list3_list4_overlap_total / list4_total) * 100.0\n",
    "    list3_list4_overlap_percent = round(numpy.mean([temp1, temp2]), 1)\n",
    "    temp1 = (list1_list2_list3_overlap_total / list1_total) * 100.0\n",
    "    temp2 = (list1_list2_list3_overlap_total / list2_total) * 100.0\n",
    "    temp3 = (list1_list2_list3_overlap_total / list3_total) * 100.0\n",
    "    list1_list2_list3_overlap_percent = round(numpy.mean([temp1, temp2, temp3]), 1)\n",
    "    temp1 = (list1_list2_list4_overlap_total / list1_total) * 100.0\n",
    "    temp2 = (list1_list2_list4_overlap_total / list2_total) * 100.0\n",
    "    temp3 = (list1_list2_list4_overlap_total / list4_total) * 100.0\n",
    "    list1_list2_list4_overlap_percent = round(numpy.mean([temp1, temp2, temp3]), 1)\n",
    "    temp1 = (list1_list3_list4_overlap_total / list1_total) * 100.0\n",
    "    temp2 = (list1_list3_list4_overlap_total / list3_total) * 100.0\n",
    "    temp3 = (list1_list3_list4_overlap_total / list4_total) * 100.0\n",
    "    list1_list3_list4_overlap_percent = round(numpy.mean([temp1, temp2, temp3]), 1)\n",
    "    temp1 = (list2_list3_list4_overlap_total / list2_total) * 100.0\n",
    "    temp2 = (list2_list3_list4_overlap_total / list3_total) * 100.0\n",
    "    temp3 = (list2_list3_list4_overlap_total / list4_total) * 100.0\n",
    "    list2_list3_list4_overlap_percent = round(numpy.mean([temp1, temp2, temp3]), 1)\n",
    "    temp1 = (all_list_overlap_total / list1_total) * 100.0\n",
    "    temp2 = (all_list_overlap_total / list2_total) * 100.0\n",
    "    temp3 = (all_list_overlap_total / list3_total) * 100.0\n",
    "    temp4 = (all_list_overlap_total / list4_total) * 100.0\n",
    "    all_list_overlap_percent = round(numpy.mean([temp1, temp2, temp3, temp4]), 1)\n",
    "    \n",
    "    # Print report to the screen\n",
    "    print('List 1 only: ' + str(list1_only_percent) + '% (' + str(int(list1_only_total)) + ')')\n",
    "    print('List 2 only: ' + str(list2_only_percent) + '% (' + str(int(list2_only_total)) + ')')\n",
    "    print('List 3 only: ' + str(list3_only_percent) + '% (' + str(int(list3_only_total)) + ')')\n",
    "    print('List 4 only: ' + str(list4_only_percent) + '% (' + str(int(list4_only_total)) + ')')\n",
    "    print('')\n",
    "    print('List 1 + List 2: ' + str(list1_list2_overlap_percent) + '% (' + str(int(list1_list2_overlap_total)) + ')')\n",
    "    print('List 1 + List 3: ' + str(list1_list3_overlap_percent) + '% (' + str(int(list1_list3_overlap_total)) + ')')\n",
    "    print('List 1 + List 4: ' + str(list1_list4_overlap_percent) + '% (' + str(int(list1_list4_overlap_total)) + ')')\n",
    "    print('List 2 + List 3: ' + str(list2_list3_overlap_percent) + '% (' + str(int(list2_list3_overlap_total)) + ')')\n",
    "    print('List 2 + List 4: ' + str(list2_list4_overlap_percent) + '% (' + str(int(list2_list4_overlap_total)) + ')')\n",
    "    print('List 3 + List 4: ' + str(list3_list4_overlap_percent) + '% (' + str(int(list3_list4_overlap_total)) + ')')\n",
    "    print('')\n",
    "    print('List 1 + List 2 + List 3: ' + str(list1_list2_list3_overlap_percent) + '% (' + str(int(list1_list2_list3_overlap_total)) + ')')\n",
    "    print('List 1 + List 2 + List 4: ' + str(list1_list2_list4_overlap_percent) + '% (' + str(int(list1_list2_list4_overlap_total)) + ')')\n",
    "    print('List 1 + List 3 + List 4: ' + str(list1_list3_list4_overlap_percent) + '% (' + str(int(list1_list3_list4_overlap_total)) + ')')\n",
    "    print('List 2 + List 3 + List 4: ' + str(list2_list3_list4_overlap_percent) + '% (' + str(int(list2_list3_list4_overlap_total)) + ')')\n",
    "    print('')\n",
    "    print('Shared: ' + str(all_list_overlap_percent) + '% (' + str(int(all_list_overlap_total)) + ')')\n",
    "\n",
    "    # Return new lists\n",
    "    return [list1_only,list2_only,list3_only,list4_only,list1_list2_overlap, list1_list3_overlap, list1_list4_overlap, list2_list3_overlap, list2_list4_overlap, list3_list4_overlap, list1_list2_list3_overlap, list1_list2_list4_overlap, list1_list3_list4_overlap, list2_list3_list4_overlap, all_list_overlap]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "List 1 only: 3.8% (17)\n",
      "List 2 only: 4.3% (21)\n",
      "List 3 only: 4.1% (19)\n",
      "List 4 only: 8.0% (40)\n",
      "\n",
      "List 1 + List 2: 4.5% (21)\n",
      "List 1 + List 3: 4.8% (22)\n",
      "List 1 + List 4: 1.3% (6)\n",
      "List 2 + List 3: 1.7% (8)\n",
      "List 2 + List 4: 8.8% (44)\n",
      "List 3 + List 4: 5.8% (28)\n",
      "\n",
      "List 1 + List 2 + List 3: 4.7% (22)\n",
      "List 1 + List 2 + List 4: 3.1% (15)\n",
      "List 1 + List 3 + List 4: 1.1% (5)\n",
      "List 2 + List 3 + List 4: 4.5% (22)\n",
      "\n",
      "Shared: 71.5% (341)\n"
     ]
    }
   ],
   "source": [
    "# Reactions\n",
    "iJO1366_m9_aerobic_reactions = [x.id for x in iJO1366_m9_aerobic.reactions]\n",
    "iJO1366_m9_anaerobic_reactions = [x.id for x in iJO1366_m9_anaerobic.reactions]\n",
    "iJO1366_lb_aerobic_reactions = [x.id for x in iJO1366_lb_aerobic.reactions]\n",
    "iJO1366_pfba_reactions = [x.id for x in iJO1366_pfba.reactions]\n",
    "\n",
    "reactions_comparisons = venn_comparison(iJO1366_pfba_reactions, iJO1366_lb_aerobic_reactions, iJO1366_m9_aerobic_reactions, iJO1366_m9_anaerobic_reactions)\n",
    "\n",
    "# List 1: pfba\n",
    "# List 2: lb_aerobic\n",
    "# List 3: m9_aerobic\n",
    "# List 4: m9_anaerobic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "List 1 only: 1.3% (6)\n",
      "List 2 only: 3.2% (16)\n",
      "List 3 only: 1.9% (9)\n",
      "List 4 only: 5.0% (25)\n",
      "\n",
      "List 1 + List 2: 2.1% (10)\n",
      "List 1 + List 3: 2.6% (12)\n",
      "List 1 + List 4: 0.6% (3)\n",
      "List 2 + List 3: 1.0% (5)\n",
      "List 2 + List 4: 6.8% (34)\n",
      "List 3 + List 4: 3.5% (17)\n",
      "\n",
      "List 1 + List 2 + List 3: 1.7% (8)\n",
      "List 1 + List 2 + List 4: 1.9% (9)\n",
      "List 1 + List 3 + List 4: 0.4% (2)\n",
      "List 2 + List 3 + List 4: 2.9% (14)\n",
      "\n",
      "Shared: 83.6% (399)\n"
     ]
    }
   ],
   "source": [
    "# Metabolites\n",
    "iJO1366_m9_aerobic_metabolites = [x.id for x in iJO1366_m9_aerobic.metabolites]\n",
    "iJO1366_m9_anaerobic_metabolites = [x.id for x in iJO1366_m9_anaerobic.metabolites]\n",
    "iJO1366_lb_aerobic_metabolites = [x.id for x in iJO1366_lb_aerobic.metabolites]\n",
    "iJO1366_pfba_metabolites = [x.id for x in iJO1366_pfba.metabolites]\n",
    "\n",
    "metabolites_comparisons = venn_comparison(iJO1366_pfba_metabolites, iJO1366_lb_aerobic_metabolites, iJO1366_m9_aerobic_metabolites, iJO1366_m9_anaerobic_metabolites)\n",
    "\n",
    "# List 1: pfba\n",
    "# List 2: lb_aerobic\n",
    "# List 3: m9_aerobic\n",
    "# List 4: m9_anaerobic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Screen context specific growth rates by each model's optimal growth\n",
    "\n",
    "# Determine bounds\n",
    "pfba_obj_val_lb = iJO1366_pfba.slim_optimize() * 0.8\n",
    "lb_aerobic_obj_val_lb = iJO1366_lb_aerobic.slim_optimize() * 0.8\n",
    "m9_aerobic_obj_val_lb = iJO1366_m9_aerobic.slim_optimize() * 0.8\n",
    "m9_anaerobic_obj_val_lb = iJO1366_m9_anaerobic.slim_optimize() * 0.8\n",
    "pfba_obj_val_ub = iJO1366_pfba.slim_optimize()\n",
    "lb_aerobic_obj_val_ub = iJO1366_lb_aerobic.slim_optimize()\n",
    "m9_aerobic_obj_val_ub = iJO1366_m9_aerobic.slim_optimize()\n",
    "m9_anaerobic_obj_val_ub = iJO1366_m9_anaerobic.slim_optimize()\n",
    "\n",
    "# Collect fluxes\n",
    "pfba_biomass = list(pfba_samples['BIOMASS_Ec_iJO1366_WT_53p95M'])\n",
    "lb_biomass = list(lb_samples['BIOMASS_Ec_iJO1366_WT_53p95M'])\n",
    "m9_aerobic_biomass = list(m9_aerobic_samples['BIOMASS_Ec_iJO1366_WT_53p95M'])\n",
    "m9_anaerobic_biomass = list(m9_anaerobic_samples['BIOMASS_Ec_iJO1366_WT_53p95M'])\n",
    "\n",
    "# Screen fluxes\n",
    "pfba_biomass = [x for x in pfba_biomass if x >= pfba_obj_val_lb and x <= pfba_obj_val_ub]\n",
    "lb_biomass = [x for x in lb_biomass if x >= lb_aerobic_obj_val_lb and x <= lb_aerobic_obj_val_ub]\n",
    "m9_aerobic_biomass = [x for x in m9_aerobic_biomass if x >= m9_aerobic_obj_val_lb and x <= m9_aerobic_obj_val_ub]\n",
    "m9_anaerobic_biomass = [x for x in m9_anaerobic_biomass if x >= m9_anaerobic_obj_val_lb and x <= m9_anaerobic_obj_val_ub]\n",
    "\n",
    "# Convert to per hour rate\n",
    "pfba_rates = [round((x / 60.0), 3) for x in pfba_biomass]\n",
    "lb_aerobic_rates = [round((x / 60.0), 3) for x in lb_biomass]\n",
    "m9_aerobic_rates = [round((x / 60.0), 3) for x in m9_aerobic_biomass]\n",
    "m9_anaerobic_rates = [round((x / 60.0), 3) for x in m9_anaerobic_biomass]\n",
    "\n",
    "# Subsample evenly\n",
    "import random\n",
    "sub_level = min([len(pfba_rates), len(lb_aerobic_rates), len(m9_aerobic_rates), len(m9_anaerobic_rates)])\n",
    "pfba_sub = random.sample(range(0,len(pfba_rates)), sub_level)\n",
    "lb_sub = random.sample(range(0,len(lb_aerobic_rates)), sub_level)\n",
    "m9a_sub = random.sample(range(0,len(m9_aerobic_rates)), sub_level)\n",
    "m9n_sub = random.sample(range(0,len(m9_anaerobic_rates)), sub_level)\n",
    "pfba_rates = [pfba_rates[i] for i in pfba_sub]\n",
    "lb_aerobic_rates = [lb_aerobic_rates[i] for i in lb_sub]\n",
    "m9_aerobic_rates = [m9_aerobic_rates[i] for i in m9a_sub]\n",
    "m9_anaerobic_rates = [m9_anaerobic_rates[i] for i in m9n_sub]\n",
    "\n",
    "# Convert to strings\n",
    "pfba_rates = [str(x) for x in pfba_rates]\n",
    "pfba_rates = 'base_pfba\\t' + '\\t'.join(pfba_rates) + '\\n'\n",
    "m9_aerobic_rates = [str(x) for x in m9_aerobic_rates]\n",
    "m9_aerobic_rates = 'm9_gluc_aerobic\\t' + '\\t'.join(m9_aerobic_rates) + '\\n'\n",
    "m9_anaerobic_rates = [str(x) for x in m9_anaerobic_rates]\n",
    "m9_anaerobic_rates = 'm9_gluc_anaerobic\\t' + '\\t'.join(m9_anaerobic_rates) + '\\n'\n",
    "lb_aerobic_rates = [str(x) for x in lb_aerobic_rates]\n",
    "lb_aerobic_rates = 'lb_aerobic\\t' + '\\t'.join(lb_aerobic_rates) + '\\n'\n",
    "\n",
    "# Write to file\n",
    "with open('/home/mjenior/Desktop/repos/Jenior_RIPTiDe_2019/data/new_growth_rates.tsv', 'w') as rates:\n",
    "    rates.write(pfba_rates)\n",
    "    rates.write(m9_aerobic_rates)\n",
    "    rates.write(m9_anaerobic_rates)\n",
    "    rates.write(lb_aerobic_rates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write contextualized models to SBMLs and JSONs\n",
    "cobra.io.write_sbml_model(iJO1366_m9_aerobic, '/home/mjenior/Desktop/repos/Jenior_RIPTiDe_2019/data/riptide_models/iJO1366_m9_aerobic.sbml')\n",
    "cobra.io.save_json_model(iJO1366_m9_aerobic, '/home/mjenior/Desktop/repos/Jenior_RIPTiDe_2019/data/riptide_models/iJO1366_m9_aerobic.json')\n",
    "cobra.io.write_sbml_model(iJO1366_m9_anaerobic, '/home/mjenior/Desktop/repos/Jenior_RIPTiDe_2019/data/riptide_models/iJO1366_m9_anaerobic.sbml')\n",
    "cobra.io.save_json_model(iJO1366_m9_anaerobic, '/home/mjenior/Desktop/repos/Jenior_RIPTiDe_2019/data/riptide_models/iJO1366_m9_anaerobic.json')\n",
    "cobra.io.write_sbml_model(iJO1366_lb_aerobic, '/home/mjenior/Desktop/repos/Jenior_RIPTiDe_2019/data/riptide_models/iJO1366_lb_aerobic.sbml')\n",
    "cobra.io.save_json_model(iJO1366_lb_aerobic, '/home/mjenior/Desktop/repos/Jenior_RIPTiDe_2019/data/riptide_models/iJO1366_lb_aerobic.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correct the sample labels\n",
    "def label_flux_samples(file_name, label):\n",
    "    new_name = file_name.rstrip('tsv') + 'format.tsv'\n",
    "    new_file = open(new_name, 'w')\n",
    "    \n",
    "    with open(file_name, 'r') as samples:\n",
    "        header = samples.readline()\n",
    "        header = 'sample\\t' + header\n",
    "        new_file.write(header)\n",
    "        current = 1\n",
    "        \n",
    "        for line in samples:\n",
    "            line = label + '_' + str(current) + '\\t' + line\n",
    "            new_file.write(line)\n",
    "            current += 1\n",
    "\n",
    "    new_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write chosen flux sample tables to tsvs\n",
    "m9_aerobic_samples.to_csv('/home/mjenior/Desktop/repos/Jenior_RIPTiDe_2019/data/flux_samples/M9_aerobic.flux_samples.tsv', sep='\\t')\n",
    "m9_anaerobic_samples.to_csv('/home/mjenior/Desktop/repos/Jenior_RIPTiDe_2019/data/flux_samples/M9_anaerobic.flux_samples.tsv', sep='\\t')\n",
    "lb_samples.to_csv('/home/mjenior/Desktop/repos/Jenior_RIPTiDe_2019/data/flux_samples/LB_aerobic.flux_samples.tsv', sep='\\t')\n",
    "pfba_samples.to_csv('/home/mjenior/Desktop/repos/Jenior_RIPTiDe_2019/data/flux_samples/pFBA.flux_samples.tsv', sep='\\t')\n",
    "\n",
    "    \n",
    "label_flux_samples('/home/mjenior/Desktop/repos/Jenior_RIPTiDe_2019/data/flux_samples/M9_aerobic.flux_samples.tsv', 'm9_aer')\n",
    "label_flux_samples('/home/mjenior/Desktop/repos/Jenior_RIPTiDe_2019/data/flux_samples/M9_anaerobic.flux_samples.tsv', 'm9_anaer')\n",
    "label_flux_samples('/home/mjenior/Desktop/repos/Jenior_RIPTiDe_2019/data/flux_samples/LB_aerobic.flux_samples.tsv', 'lb')\n",
    "label_flux_samples('/home/mjenior/Desktop/repos/Jenior_RIPTiDe_2019/data/flux_samples/pFBA.flux_samples.tsv', 'pfba')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Context-specific Essentiality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cobra.flux_analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Essential genes: 105\n"
     ]
    }
   ],
   "source": [
    "iJO1366_essential_genes = cobra.flux_analysis.find_essential_genes(iJO1366)\n",
    "print('Essential genes: ' + str(len(iJO1366_essential_genes)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Essential genes: 226\n"
     ]
    }
   ],
   "source": [
    "iJO1366_pfba_essential_genes = cobra.flux_analysis.find_essential_genes(iJO1366_pfba)\n",
    "iJO1366_pfba_essential_genes = set([x.id for x in iJO1366_pfba_essential_genes])\n",
    "print('Essential genes: ' + str(len(iJO1366_pfba_essential_genes)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Essential genes: 227\n"
     ]
    }
   ],
   "source": [
    "iJO1366_lb_aerobic_essential_genes = cobra.flux_analysis.find_essential_genes(iJO1366_lb_aerobic)\n",
    "iJO1366_lb_aerobic_essential_genes = set([x.id for x in iJO1366_lb_aerobic_essential_genes])\n",
    "print('Essential genes: ' + str(len(iJO1366_lb_aerobic_essential_genes)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Essential genes: 232\n"
     ]
    }
   ],
   "source": [
    "iJO1366_m9_aerobic_essential_genes = cobra.flux_analysis.find_essential_genes(iJO1366_m9_aerobic)\n",
    "iJO1366_m9_aerobic_essential_genes = set([x.id for x in iJO1366_m9_aerobic_essential_genes])\n",
    "print('Essential genes: ' + str(len(iJO1366_m9_aerobic_essential_genes)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Essential genes: 229\n"
     ]
    }
   ],
   "source": [
    "iJO1366_m9_anaerobic_essential_genes = cobra.flux_analysis.find_essential_genes(iJO1366_m9_anaerobic)\n",
    "iJO1366_m9_anaerobic_essential_genes = set([x.id for x in iJO1366_m9_anaerobic_essential_genes])\n",
    "print('Essential genes: ' + str(len(iJO1366_m9_anaerobic_essential_genes)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'venn_comparison' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-5d857bc3bd67>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0messentiality_comparisons\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvenn_comparison\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miJO1366_pfba_essential_genes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miJO1366_lb_aerobic_essential_genes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miJO1366_m9_aerobic_essential_genes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miJO1366_m9_anaerobic_essential_genes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;31m# List 1: pfba\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# List 2: lb_aerobic\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# List 3: m9_aerobic\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# List 4: m9_anaerobic\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'venn_comparison' is not defined"
     ]
    }
   ],
   "source": [
    "essentiality_comparisons = venn_comparison(iJO1366_pfba_essential_genes, iJO1366_lb_aerobic_essential_genes, iJO1366_m9_aerobic_essential_genes, iJO1366_m9_anaerobic_essential_genes)\n",
    "# List 1: pfba\n",
    "# List 2: lb_aerobic\n",
    "# List 3: m9_aerobic\n",
    "# List 4: m9_anaerobic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Essential in all GENREs: 178\n"
     ]
    }
   ],
   "source": [
    "# Find those genes shared in all models\n",
    "core_essential = iJO1366_pfba_essential_genes.intersection(iJO1366_lb_aerobic_essential_genes)\n",
    "core_essential = core_essential.intersection(iJO1366_m9_aerobic_essential_genes)\n",
    "core_essential = core_essential.intersection(iJO1366_m9_anaerobic_essential_genes)\n",
    "print('Essential in all GENREs: ' + str(len(core_essential)))\n",
    "\n",
    "# Substract as background from each\n",
    "iJO1366_pfba_essential_genes = iJO1366_pfba_essential_genes.difference(core_essential)\n",
    "iJO1366_lb_aerobic_essential_genes = iJO1366_lb_aerobic_essential_genes.difference(core_essential)\n",
    "iJO1366_m9_aerobic_essential_genes = iJO1366_m9_aerobic_essential_genes.difference(core_essential)\n",
    "iJO1366_m9_anaerobic_essential_genes = iJO1366_m9_anaerobic_essential_genes.difference(core_essential)\n",
    "\n",
    "# Find non-essentiality across models\n",
    "iJO1366_pfba_genes = set([x.id for x in iJO1366_pfba.genes])\n",
    "iJO1366_lb_aerobic_genes = set([x.id for x in iJO1366_lb_aerobic.genes])\n",
    "iJO1366_m9_aerobic_genes = set([x.id for x in iJO1366_m9_aerobic.genes])\n",
    "iJO1366_m9_anaerobic_genes = set([x.id for x in iJO1366_m9_anaerobic.genes])\n",
    "\n",
    "# Compare overlapping genes\n",
    "total_genes = set()\n",
    "total_genes |= iJO1366_pfba_essential_genes\n",
    "total_genes |= iJO1366_lb_aerobic_essential_genes\n",
    "total_genes |= iJO1366_m9_aerobic_essential_genes\n",
    "total_genes |= iJO1366_m9_anaerobic_essential_genes\n",
    "with open('/home/mjenior/Desktop/repos/Jenior_RIPTiDe_2019/data/essentiality_test.tsv', 'w') as outfile:\n",
    "    outfile.write('gene\\tpfba\\tlb_aerobic\\tm9_aerobic\\tm9_anaerobic\\n')\n",
    "    for gene in total_genes:\n",
    "        entry = ['filler','filler','filler','filler']\n",
    "        \n",
    "        if gene in iJO1366_pfba_essential_genes:\n",
    "            entry[0] = 2\n",
    "        elif gene in iJO1366_pfba_genes:\n",
    "            entry[0] = 1\n",
    "        else:\n",
    "            entry[0] = 0\n",
    "            \n",
    "        if gene in iJO1366_lb_aerobic_essential_genes:\n",
    "            entry[1] = 2\n",
    "        elif gene in iJO1366_lb_aerobic_genes:\n",
    "            entry[1] = 1\n",
    "        else:\n",
    "            entry[1] = 0\n",
    "            \n",
    "        if gene in iJO1366_m9_aerobic_essential_genes:\n",
    "            entry[2] = 2\n",
    "        elif gene in iJO1366_m9_aerobic_genes:\n",
    "            entry[2] = 1\n",
    "        else:\n",
    "            entry[2] = 0\n",
    "            \n",
    "        if gene in iJO1366_m9_anaerobic_essential_genes:\n",
    "            entry[3] = 2\n",
    "        elif gene in iJO1366_m9_anaerobic_genes:\n",
    "            entry[3] = 1\n",
    "        else:\n",
    "            entry[3] = 0\n",
    "            \n",
    "        entry = gene + '\\t' + '\\t'.join([str(x) for x in entry]) + '\\n'\n",
    "        outfile.write(entry)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Metatranscriptomic analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_source(model, met_id):\n",
    "    generating = set()\n",
    "    for rxn in model.reactions:\n",
    "        for met in rxn.products:\n",
    "            if met_id in met.id:\n",
    "                generating |= set([rxn.id])\n",
    "        \n",
    "    print('Metabolite sources: ' + str(len(generating)))\n",
    "    return generating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "clinda_k12_metaT = {}\n",
    "with open('/home/mjenior/Desktop/repos/Jenior_RIPTiDe_2019/data/transcript/clinda_k12.mapped.norm.tsv', 'r') as transcription:\n",
    "    header = transcription.readline()\n",
    "    for line in transcription:\n",
    "        line = line.split()\n",
    "        clinda_k12_metaT[line[0]] = float(line[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing model and parsing transcriptome...\n",
      "Pruning zero flux subnetworks...\n",
      "Sampling context-specific solution space (longest step)...\n",
      "\n",
      "Reactions pruned to 490 from 2583 (81.0% reduction)\n",
      "Metabolites pruned to 493 from 1805 (72.7% reduction)\n",
      "\n",
      "Flux through the objective REDUCED to 53.17 from 105.765 (49.73% shift)\n",
      "Solution space ellipsoid volume DECREASED to ~0.306 from ~9.161 (96.66% shift)\n",
      "\n",
      "RIPTiDe completed in 4.9 minutes\n"
     ]
    }
   ],
   "source": [
    "iJO1366_invivo_metaT, invivo_metaT_samples = riptide(iJO1366, clinda_k12_metaT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.538, 0.578, 0.886]\n"
     ]
    }
   ],
   "source": [
    "invivo_rates = collect_growth_rates(invivo_metaT_samples, 'BIOMASS_Ec_iJO1366_WT_53p95M')\n",
    "print([min(invivo_rates), numpy.median(invivo_rates), max(invivo_rates)])\n",
    "with open('/home/mjenior/Desktop/repos/Jenior_RIPTiDe_2019/data/invivo_growth_rates.tsv', 'w') as output_file:\n",
    "    for x in invivo_rates: output_file.write(str(x) + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metabolite sources: 3\n"
     ]
    }
   ],
   "source": [
    "invivo_anaerobic_atp = find_source(iJO1366_invivo_metaT, 'atp_c')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "vitro_ex = set([x.id for x in iJO1366_m9_anaerobic.reactions if 'EX_' in x.id])\n",
    "vivo_ex = set([x.id for x in iJO1366_invivo_metaT.reactions if 'EX_' in x.id])\n",
    "\n",
    "vitro_ex_only = vitro_ex.difference(vivo_ex)\n",
    "vitro_ex_only_input = set()\n",
    "for y in vitro_ex_only:\n",
    "    if abs(iJO1366_m9_anaerobic.reactions.get_by_id(y).lower_bound) > abs(iJO1366_m9_anaerobic.reactions.get_by_id(y).upper_bound):\n",
    "        vitro_ex_only_input |= set([y])\n",
    "\n",
    "vivo_ex_only = vivo_ex.difference(vitro_ex)\n",
    "vivo_ex_only_input = set()\n",
    "for y in vivo_ex_only:\n",
    "    if abs(iJO1366_invivo_metaT.reactions.get_by_id(y).lower_bound) > abs(iJO1366_invivo_metaT.reactions.get_by_id(y).upper_bound):\n",
    "        vivo_ex_only_input |= set([y])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quinate\n",
      "Glycerol 3-phosphate\n",
      "Glycerophosphoserine\n",
      "L-Leucine\n",
      "L-tartrate\n",
      "Ethanol\n",
      "Guanosine\n",
      "D-Fructose 6-phosphate\n",
      "Allantoin\n"
     ]
    }
   ],
   "source": [
    "for x in vitro_ex_only_input: print(iJO1366_m9_anaerobic.reactions.get_by_id(x).reactants[0].name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "L-Serine\n",
      "Deoxyuridine\n",
      "Trehalose\n",
      "Deoxyguanosine\n",
      "Glycine\n",
      "Pyridoxine\n",
      "Myo-Inositol hexakisphosphate\n",
      "Shikimate\n"
     ]
    }
   ],
   "source": [
    "for x in vivo_ex_only_input: print(iJO1366_invivo_metaT.reactions.get_by_id(x).reactants[0].name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.11 hours\n"
     ]
    }
   ],
   "source": [
    "max_doubling_time(iJO1366_invivo_metaT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write flux sample tables to tsv\n",
    "m9_anaerobic_samples.to_csv('/home/mjenior/Desktop/repos/Jenior_RIPTiDe_2019/data/flux_samples/invitro.flux_samples.tsv', sep='\\t')\n",
    "label_flux_samples('/home/mjenior/Desktop/repos/Jenior_RIPTiDe_2019/data/flux_samples/invitro.flux_samples.tsv', 'invitro')\n",
    "\n",
    "invivo_metaT_samples.to_csv('/home/mjenior/Desktop/repos/Jenior_RIPTiDe_2019/data/flux_samples/invivo.flux_samples.tsv', sep='\\t')\n",
    "label_flux_samples('/home/mjenior/Desktop/repos/Jenior_RIPTiDe_2019/data/flux_samples/invivo.flux_samples.tsv', 'invivo')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[86.41, 105.13, 111.6]\n",
      "[0.538, 0.571, 0.694]\n"
     ]
    }
   ],
   "source": [
    "invivo_metaT_times = collect_doubling_times(invivo_metaT_samples, 'BIOMASS_Ec_iJO1366_WT_53p95M')\n",
    "print([min(invivo_metaT_times), numpy.median(invivo_metaT_times), max(invivo_metaT_times)])\n",
    "invivo_metaT_rates = collect_growth_rates(invivo_metaT_samples, 'BIOMASS_Ec_iJO1366_WT_53p95M')\n",
    "print([min(invivo_metaT_rates), numpy.median(invivo_metaT_rates), max(invivo_metaT_rates)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "m9 = cobra.io.read_sbml_model('/home/mjenior/Desktop/repos/Jenior_RIPTiDe_2019/data/riptide_models/iJO1366_m9_aerobic.sbml')\n",
    "lb = cobra.io.read_sbml_model('/home/mjenior/Desktop/repos/Jenior_RIPTiDe_2019/data/riptide_models/iJO1366_lb_aerobic.sbml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metabolite sources: 4\n",
      "Metabolite sources: 3\n"
     ]
    }
   ],
   "source": [
    "m9_nadph = find_source(m9, 'nadph_c')\n",
    "lb_nadph = find_source(lb, 'nadph_c')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing Previous Integration Algorithms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iJO1366 = cobra.io.read_sbml_model('/home/mjenior/Desktop/repos/Jenior_RIPTiDe_2019/data/iJO1366.xml')\n",
    "iJO1366.objective = iJO1366.reactions.BIOMASS_Ec_iJO1366_WT_53p95M\n",
    "\n",
    "# Open all exchanges\n",
    "exchanges = set()\n",
    "for rxn in iJO1366.reactions:\n",
    "    if len(rxn.reactants) == 0 or len(rxn.products) == 0:\n",
    "        rxn.bounds = (min(rxn.lower_bound, -1000), max(rxn.upper_bound, 1000))\n",
    "        exchanges |= set([rxn.id])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "(function(root) {\n",
       "  function now() {\n",
       "    return new Date();\n",
       "  }\n",
       "\n",
       "  var force = true;\n",
       "\n",
       "  if (typeof (root._bokeh_onload_callbacks) === \"undefined\" || force === true) {\n",
       "    root._bokeh_onload_callbacks = [];\n",
       "    root._bokeh_is_loading = undefined;\n",
       "  }\n",
       "\n",
       "  var JS_MIME_TYPE = 'application/javascript';\n",
       "  var HTML_MIME_TYPE = 'text/html';\n",
       "  var EXEC_MIME_TYPE = 'application/vnd.bokehjs_exec.v0+json';\n",
       "  var CLASS_NAME = 'output_bokeh rendered_html';\n",
       "\n",
       "  /**\n",
       "   * Render data to the DOM node\n",
       "   */\n",
       "  function render(props, node) {\n",
       "    var script = document.createElement(\"script\");\n",
       "    node.appendChild(script);\n",
       "  }\n",
       "\n",
       "  /**\n",
       "   * Handle when an output is cleared or removed\n",
       "   */\n",
       "  function handleClearOutput(event, handle) {\n",
       "    var cell = handle.cell;\n",
       "\n",
       "    var id = cell.output_area._bokeh_element_id;\n",
       "    var server_id = cell.output_area._bokeh_server_id;\n",
       "    // Clean up Bokeh references\n",
       "    if (id !== undefined) {\n",
       "      Bokeh.index[id].model.document.clear();\n",
       "      delete Bokeh.index[id];\n",
       "    }\n",
       "\n",
       "    if (server_id !== undefined) {\n",
       "      // Clean up Bokeh references\n",
       "      var cmd = \"from bokeh.io.state import curstate; print(curstate().uuid_to_server['\" + server_id + \"'].get_sessions()[0].document.roots[0]._id)\";\n",
       "      cell.notebook.kernel.execute(cmd, {\n",
       "        iopub: {\n",
       "          output: function(msg) {\n",
       "            var element_id = msg.content.text.trim();\n",
       "            Bokeh.index[element_id].model.document.clear();\n",
       "            delete Bokeh.index[element_id];\n",
       "          }\n",
       "        }\n",
       "      });\n",
       "      // Destroy server and session\n",
       "      var cmd = \"import bokeh.io.notebook as ion; ion.destroy_server('\" + server_id + \"')\";\n",
       "      cell.notebook.kernel.execute(cmd);\n",
       "    }\n",
       "  }\n",
       "\n",
       "  /**\n",
       "   * Handle when a new output is added\n",
       "   */\n",
       "  function handleAddOutput(event, handle) {\n",
       "    var output_area = handle.output_area;\n",
       "    var output = handle.output;\n",
       "\n",
       "    // limit handleAddOutput to display_data with EXEC_MIME_TYPE content only\n",
       "    if ((output.output_type != \"display_data\") || (!output.data.hasOwnProperty(EXEC_MIME_TYPE))) {\n",
       "      return\n",
       "    }\n",
       "\n",
       "    var toinsert = output_area.element.find(`.${CLASS_NAME.split(' ')[0]}`);\n",
       "\n",
       "    if (output.metadata[EXEC_MIME_TYPE][\"id\"] !== undefined) {\n",
       "      toinsert[0].firstChild.textContent = output.data[JS_MIME_TYPE];\n",
       "      // store reference to embed id on output_area\n",
       "      output_area._bokeh_element_id = output.metadata[EXEC_MIME_TYPE][\"id\"];\n",
       "    }\n",
       "    if (output.metadata[EXEC_MIME_TYPE][\"server_id\"] !== undefined) {\n",
       "      var bk_div = document.createElement(\"div\");\n",
       "      bk_div.innerHTML = output.data[HTML_MIME_TYPE];\n",
       "      var script_attrs = bk_div.children[0].attributes;\n",
       "      for (var i = 0; i < script_attrs.length; i++) {\n",
       "        toinsert[0].firstChild.setAttribute(script_attrs[i].name, script_attrs[i].value);\n",
       "      }\n",
       "      // store reference to server id on output_area\n",
       "      output_area._bokeh_server_id = output.metadata[EXEC_MIME_TYPE][\"server_id\"];\n",
       "    }\n",
       "  }\n",
       "\n",
       "  function register_renderer(events, OutputArea) {\n",
       "\n",
       "    function append_mime(data, metadata, element) {\n",
       "      // create a DOM node to render to\n",
       "      var toinsert = this.create_output_subarea(\n",
       "        metadata,\n",
       "        CLASS_NAME,\n",
       "        EXEC_MIME_TYPE\n",
       "      );\n",
       "      this.keyboard_manager.register_events(toinsert);\n",
       "      // Render to node\n",
       "      var props = {data: data, metadata: metadata[EXEC_MIME_TYPE]};\n",
       "      render(props, toinsert[0]);\n",
       "      element.append(toinsert);\n",
       "      return toinsert\n",
       "    }\n",
       "\n",
       "    /* Handle when an output is cleared or removed */\n",
       "    events.on('clear_output.CodeCell', handleClearOutput);\n",
       "    events.on('delete.Cell', handleClearOutput);\n",
       "\n",
       "    /* Handle when a new output is added */\n",
       "    events.on('output_added.OutputArea', handleAddOutput);\n",
       "\n",
       "    /**\n",
       "     * Register the mime type and append_mime function with output_area\n",
       "     */\n",
       "    OutputArea.prototype.register_mime_type(EXEC_MIME_TYPE, append_mime, {\n",
       "      /* Is output safe? */\n",
       "      safe: true,\n",
       "      /* Index of renderer in `output_area.display_order` */\n",
       "      index: 0\n",
       "    });\n",
       "  }\n",
       "\n",
       "  // register the mime type if in Jupyter Notebook environment and previously unregistered\n",
       "  if (root.Jupyter !== undefined) {\n",
       "    var events = require('base/js/events');\n",
       "    var OutputArea = require('notebook/js/outputarea').OutputArea;\n",
       "\n",
       "    if (OutputArea.prototype.mime_types().indexOf(EXEC_MIME_TYPE) == -1) {\n",
       "      register_renderer(events, OutputArea);\n",
       "    }\n",
       "  }\n",
       "\n",
       "  \n",
       "  if (typeof (root._bokeh_timeout) === \"undefined\" || force === true) {\n",
       "    root._bokeh_timeout = Date.now() + 5000;\n",
       "    root._bokeh_failed_load = false;\n",
       "  }\n",
       "\n",
       "  var NB_LOAD_WARNING = {'data': {'text/html':\n",
       "     \"<div style='background-color: #fdd'>\\n\"+\n",
       "     \"<p>\\n\"+\n",
       "     \"BokehJS does not appear to have successfully loaded. If loading BokehJS from CDN, this \\n\"+\n",
       "     \"may be due to a slow or bad network connection. Possible fixes:\\n\"+\n",
       "     \"</p>\\n\"+\n",
       "     \"<ul>\\n\"+\n",
       "     \"<li>re-rerun `output_notebook()` to attempt to load from CDN again, or</li>\\n\"+\n",
       "     \"<li>use INLINE resources instead, as so:</li>\\n\"+\n",
       "     \"</ul>\\n\"+\n",
       "     \"<code>\\n\"+\n",
       "     \"from bokeh.resources import INLINE\\n\"+\n",
       "     \"output_notebook(resources=INLINE)\\n\"+\n",
       "     \"</code>\\n\"+\n",
       "     \"</div>\"}};\n",
       "\n",
       "  function display_loaded() {\n",
       "    var el = document.getElementById(null);\n",
       "    if (el != null) {\n",
       "      el.textContent = \"BokehJS is loading...\";\n",
       "    }\n",
       "    if (root.Bokeh !== undefined) {\n",
       "      if (el != null) {\n",
       "        el.textContent = \"BokehJS \" + root.Bokeh.version + \" successfully loaded.\";\n",
       "      }\n",
       "    } else if (Date.now() < root._bokeh_timeout) {\n",
       "      setTimeout(display_loaded, 100)\n",
       "    }\n",
       "  }\n",
       "\n",
       "\n",
       "  function run_callbacks() {\n",
       "    try {\n",
       "      root._bokeh_onload_callbacks.forEach(function(callback) { callback() });\n",
       "    }\n",
       "    finally {\n",
       "      delete root._bokeh_onload_callbacks\n",
       "    }\n",
       "    console.info(\"Bokeh: all callbacks have finished\");\n",
       "  }\n",
       "\n",
       "  function load_libs(js_urls, callback) {\n",
       "    root._bokeh_onload_callbacks.push(callback);\n",
       "    if (root._bokeh_is_loading > 0) {\n",
       "      console.log(\"Bokeh: BokehJS is being loaded, scheduling callback at\", now());\n",
       "      return null;\n",
       "    }\n",
       "    if (js_urls == null || js_urls.length === 0) {\n",
       "      run_callbacks();\n",
       "      return null;\n",
       "    }\n",
       "    console.log(\"Bokeh: BokehJS not loaded, scheduling load and callback at\", now());\n",
       "    root._bokeh_is_loading = js_urls.length;\n",
       "    for (var i = 0; i < js_urls.length; i++) {\n",
       "      var url = js_urls[i];\n",
       "      var s = document.createElement('script');\n",
       "      s.src = url;\n",
       "      s.async = false;\n",
       "      s.onreadystatechange = s.onload = function() {\n",
       "        root._bokeh_is_loading--;\n",
       "        if (root._bokeh_is_loading === 0) {\n",
       "          console.log(\"Bokeh: all BokehJS libraries loaded\");\n",
       "          run_callbacks()\n",
       "        }\n",
       "      };\n",
       "      s.onerror = function() {\n",
       "        console.warn(\"failed to load library \" + url);\n",
       "      };\n",
       "      console.log(\"Bokeh: injecting script tag for BokehJS library: \", url);\n",
       "      document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
       "    }\n",
       "  };\n",
       "\n",
       "  var js_urls = [\"https://cdn.pydata.org/bokeh/release/bokeh-0.12.10.min.js\", \"https://cdn.pydata.org/bokeh/release/bokeh-widgets-0.12.10.min.js\", \"https://cdn.pydata.org/bokeh/release/bokeh-tables-0.12.10.min.js\", \"https://cdn.pydata.org/bokeh/release/bokeh-gl-0.12.10.min.js\"];\n",
       "\n",
       "  var inline_js = [\n",
       "    function(Bokeh) {\n",
       "      Bokeh.set_log_level(\"info\");\n",
       "    },\n",
       "    \n",
       "    function(Bokeh) {\n",
       "      \n",
       "    },\n",
       "    function(Bokeh) {\n",
       "      console.log(\"Bokeh: injecting CSS: https://cdn.pydata.org/bokeh/release/bokeh-0.12.10.min.css\");\n",
       "      Bokeh.embed.inject_css(\"https://cdn.pydata.org/bokeh/release/bokeh-0.12.10.min.css\");\n",
       "      console.log(\"Bokeh: injecting CSS: https://cdn.pydata.org/bokeh/release/bokeh-widgets-0.12.10.min.css\");\n",
       "      Bokeh.embed.inject_css(\"https://cdn.pydata.org/bokeh/release/bokeh-widgets-0.12.10.min.css\");\n",
       "      console.log(\"Bokeh: injecting CSS: https://cdn.pydata.org/bokeh/release/bokeh-tables-0.12.10.min.css\");\n",
       "      Bokeh.embed.inject_css(\"https://cdn.pydata.org/bokeh/release/bokeh-tables-0.12.10.min.css\");\n",
       "    }\n",
       "  ];\n",
       "\n",
       "  function run_inline_js() {\n",
       "    \n",
       "    if ((root.Bokeh !== undefined) || (force === true)) {\n",
       "      for (var i = 0; i < inline_js.length; i++) {\n",
       "        inline_js[i].call(root, root.Bokeh);\n",
       "      }} else if (Date.now() < root._bokeh_timeout) {\n",
       "      setTimeout(run_inline_js, 100);\n",
       "    } else if (!root._bokeh_failed_load) {\n",
       "      console.log(\"Bokeh: BokehJS failed to load within specified timeout.\");\n",
       "      root._bokeh_failed_load = true;\n",
       "    } else if (force !== true) {\n",
       "      var cell = $(document.getElementById(null)).parents('.cell').data().cell;\n",
       "      cell.output_area.append_execute_result(NB_LOAD_WARNING)\n",
       "    }\n",
       "\n",
       "  }\n",
       "\n",
       "  if (root._bokeh_is_loading === 0) {\n",
       "    console.log(\"Bokeh: BokehJS loaded, going straight to plotting\");\n",
       "    run_inline_js();\n",
       "  } else {\n",
       "    load_libs(js_urls, function() {\n",
       "      console.log(\"Bokeh: BokehJS plotting callback run at\", now());\n",
       "      run_inline_js();\n",
       "    });\n",
       "  }\n",
       "}(window));"
      ],
      "application/vnd.bokehjs_load.v0+json": "\n(function(root) {\n  function now() {\n    return new Date();\n  }\n\n  var force = true;\n\n  if (typeof (root._bokeh_onload_callbacks) === \"undefined\" || force === true) {\n    root._bokeh_onload_callbacks = [];\n    root._bokeh_is_loading = undefined;\n  }\n\n  \n\n  \n  if (typeof (root._bokeh_timeout) === \"undefined\" || force === true) {\n    root._bokeh_timeout = Date.now() + 5000;\n    root._bokeh_failed_load = false;\n  }\n\n  var NB_LOAD_WARNING = {'data': {'text/html':\n     \"<div style='background-color: #fdd'>\\n\"+\n     \"<p>\\n\"+\n     \"BokehJS does not appear to have successfully loaded. If loading BokehJS from CDN, this \\n\"+\n     \"may be due to a slow or bad network connection. Possible fixes:\\n\"+\n     \"</p>\\n\"+\n     \"<ul>\\n\"+\n     \"<li>re-rerun `output_notebook()` to attempt to load from CDN again, or</li>\\n\"+\n     \"<li>use INLINE resources instead, as so:</li>\\n\"+\n     \"</ul>\\n\"+\n     \"<code>\\n\"+\n     \"from bokeh.resources import INLINE\\n\"+\n     \"output_notebook(resources=INLINE)\\n\"+\n     \"</code>\\n\"+\n     \"</div>\"}};\n\n  function display_loaded() {\n    var el = document.getElementById(null);\n    if (el != null) {\n      el.textContent = \"BokehJS is loading...\";\n    }\n    if (root.Bokeh !== undefined) {\n      if (el != null) {\n        el.textContent = \"BokehJS \" + root.Bokeh.version + \" successfully loaded.\";\n      }\n    } else if (Date.now() < root._bokeh_timeout) {\n      setTimeout(display_loaded, 100)\n    }\n  }\n\n\n  function run_callbacks() {\n    try {\n      root._bokeh_onload_callbacks.forEach(function(callback) { callback() });\n    }\n    finally {\n      delete root._bokeh_onload_callbacks\n    }\n    console.info(\"Bokeh: all callbacks have finished\");\n  }\n\n  function load_libs(js_urls, callback) {\n    root._bokeh_onload_callbacks.push(callback);\n    if (root._bokeh_is_loading > 0) {\n      console.log(\"Bokeh: BokehJS is being loaded, scheduling callback at\", now());\n      return null;\n    }\n    if (js_urls == null || js_urls.length === 0) {\n      run_callbacks();\n      return null;\n    }\n    console.log(\"Bokeh: BokehJS not loaded, scheduling load and callback at\", now());\n    root._bokeh_is_loading = js_urls.length;\n    for (var i = 0; i < js_urls.length; i++) {\n      var url = js_urls[i];\n      var s = document.createElement('script');\n      s.src = url;\n      s.async = false;\n      s.onreadystatechange = s.onload = function() {\n        root._bokeh_is_loading--;\n        if (root._bokeh_is_loading === 0) {\n          console.log(\"Bokeh: all BokehJS libraries loaded\");\n          run_callbacks()\n        }\n      };\n      s.onerror = function() {\n        console.warn(\"failed to load library \" + url);\n      };\n      console.log(\"Bokeh: injecting script tag for BokehJS library: \", url);\n      document.getElementsByTagName(\"head\")[0].appendChild(s);\n    }\n  };\n\n  var js_urls = [\"https://cdn.pydata.org/bokeh/release/bokeh-0.12.10.min.js\", \"https://cdn.pydata.org/bokeh/release/bokeh-widgets-0.12.10.min.js\", \"https://cdn.pydata.org/bokeh/release/bokeh-tables-0.12.10.min.js\", \"https://cdn.pydata.org/bokeh/release/bokeh-gl-0.12.10.min.js\"];\n\n  var inline_js = [\n    function(Bokeh) {\n      Bokeh.set_log_level(\"info\");\n    },\n    \n    function(Bokeh) {\n      \n    },\n    function(Bokeh) {\n      console.log(\"Bokeh: injecting CSS: https://cdn.pydata.org/bokeh/release/bokeh-0.12.10.min.css\");\n      Bokeh.embed.inject_css(\"https://cdn.pydata.org/bokeh/release/bokeh-0.12.10.min.css\");\n      console.log(\"Bokeh: injecting CSS: https://cdn.pydata.org/bokeh/release/bokeh-widgets-0.12.10.min.css\");\n      Bokeh.embed.inject_css(\"https://cdn.pydata.org/bokeh/release/bokeh-widgets-0.12.10.min.css\");\n      console.log(\"Bokeh: injecting CSS: https://cdn.pydata.org/bokeh/release/bokeh-tables-0.12.10.min.css\");\n      Bokeh.embed.inject_css(\"https://cdn.pydata.org/bokeh/release/bokeh-tables-0.12.10.min.css\");\n    }\n  ];\n\n  function run_inline_js() {\n    \n    if ((root.Bokeh !== undefined) || (force === true)) {\n      for (var i = 0; i < inline_js.length; i++) {\n        inline_js[i].call(root, root.Bokeh);\n      }} else if (Date.now() < root._bokeh_timeout) {\n      setTimeout(run_inline_js, 100);\n    } else if (!root._bokeh_failed_load) {\n      console.log(\"Bokeh: BokehJS failed to load within specified timeout.\");\n      root._bokeh_failed_load = true;\n    } else if (force !== true) {\n      var cell = $(document.getElementById(null)).parents('.cell').data().cell;\n      cell.output_area.append_execute_result(NB_LOAD_WARNING)\n    }\n\n  }\n\n  if (root._bokeh_is_loading === 0) {\n    console.log(\"Bokeh: BokehJS loaded, going straight to plotting\");\n    run_inline_js();\n  } else {\n    load_libs(js_urls, function() {\n      console.log(\"Bokeh: BokehJS plotting callback run at\", now());\n      run_inline_js();\n    });\n  }\n}(window));"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mjenior/anaconda2/lib/python2.7/site-packages/driven-0.0.3-py2.7.egg/driven/data_sets/expression_profile.py:67: FutureWarning:\n",
      "\n",
      "from_csv is deprecated. Please use read_csv(...) instead. Note that some of the default arguments are different, so please refer to the documentation for from_csv when changing your function calls\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Comparison to GIMME and iMAT\n",
    "import copy\n",
    "import cobra\n",
    "from driven.flux_analysis.transcriptomics import *\n",
    "\n",
    "# Read in formatted data\n",
    "m9_aerobic_driven = ExpressionProfile.from_csv('/home/mjenior/Desktop/m9_aerobic_expression.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iMAT finished in 44.0 seconds\n"
     ]
    }
   ],
   "source": [
    "# iMAT\n",
    "start_time = time.time()\n",
    "\n",
    "iJO1366_imat_result = imat(iJO1366, expression_profile=m9_aerobic_driven, low_cutoff=102, high_cutoff=822)\n",
    "\n",
    "duration = time.time() - start_time\n",
    "duration = round(duration)\n",
    "\n",
    "print('iMAT finished in ' + str(duration) + ' seconds')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "97\n"
     ]
    }
   ],
   "source": [
    "# Check for overlap with lowly expressed reactions and gapfilled\n",
    "from cobra.flux_analysis.parsimonious import *\n",
    "\n",
    "imat_pfba = pfba(iJO1366, fraction_of_optimum=0.8)\n",
    "test1 = imat_pfba.fluxes[imat_pfba.fluxes > 0.0]\n",
    "test1 = set(test1.index)\n",
    "\n",
    "test2 = set()\n",
    "for index in iJO1366_imat_result.lowly_express.keys():\n",
    "    if iJO1366_imat_result.lowly_express[index] == True:\n",
    "        test2 |= set([index])\n",
    "\n",
    "gapfilled_imat = test1.intersection(test2)\n",
    "print(len(gapfilled_imat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'3PEPTabcpp',\n",
       " 'ADCL',\n",
       " 'ADCS',\n",
       " 'ADOCBLabcpp',\n",
       " 'ADOCBLtonex',\n",
       " 'AGPAT160',\n",
       " 'AGPAT161',\n",
       " 'AGPAT181',\n",
       " 'ALLTN',\n",
       " 'ALLTNt2rpp',\n",
       " 'ARGORNt7pp',\n",
       " 'ASNt2rpp',\n",
       " 'BMOGDS1',\n",
       " 'BMOGDS2',\n",
       " 'CLt3_2pp',\n",
       " 'CPMPS',\n",
       " 'CPPPGO',\n",
       " 'CU2tpp',\n",
       " 'DHFR',\n",
       " 'DHNAOT4',\n",
       " 'DHNPA2r',\n",
       " 'DPCOAK',\n",
       " 'DRPA',\n",
       " 'DTMPK',\n",
       " 'FACOAE160',\n",
       " 'FACOAE161',\n",
       " 'FACOAE181',\n",
       " 'FACOAL160t2pp',\n",
       " 'FACOAL161t2pp',\n",
       " 'FACOAL180t2pp',\n",
       " 'FACOAL181t2pp',\n",
       " 'FCLT',\n",
       " 'FE2tpp',\n",
       " 'FEENTERabcpp',\n",
       " 'FESR',\n",
       " 'FLDR2',\n",
       " 'G3PAT160',\n",
       " 'G3PAT161',\n",
       " 'G3PAT181',\n",
       " 'G6Pt6_2pp',\n",
       " 'GAM6Pt6_2pp',\n",
       " 'GLUt2rpp',\n",
       " 'GLUt4pp',\n",
       " 'GLYC3Pt6pp',\n",
       " 'GLYCDx',\n",
       " 'GSNt2pp',\n",
       " 'GTHRDabcpp',\n",
       " 'HPPK2',\n",
       " 'I2FE2SS',\n",
       " 'I2FE2SS2',\n",
       " 'ILEt2rpp',\n",
       " 'INDOLEt2rpp',\n",
       " 'LEUt2rpp',\n",
       " 'LIPAMPL',\n",
       " 'LIPATPT',\n",
       " 'MECDPS',\n",
       " 'MEPCT',\n",
       " 'METabcpp',\n",
       " 'MN2tpp',\n",
       " 'MOADSUx',\n",
       " 'MOCDS',\n",
       " 'MOGDS',\n",
       " 'MPTAT',\n",
       " 'MPTG',\n",
       " 'MPTG2',\n",
       " 'MPTS',\n",
       " 'MPTSS',\n",
       " 'MTHFR2',\n",
       " 'NADH16pp',\n",
       " 'NADH17pp',\n",
       " 'NADK',\n",
       " 'NO2t2rpp',\n",
       " 'NO3R1pp',\n",
       " 'NO3R2pp',\n",
       " 'NO3t7pp',\n",
       " 'NTRIR2x',\n",
       " 'OPHBDC',\n",
       " 'PFL',\n",
       " 'PGPP160',\n",
       " 'PGPP161',\n",
       " 'PGPP181',\n",
       " 'PGSA160',\n",
       " 'PGSA161',\n",
       " 'PGSA181',\n",
       " 'PNTOt4pp',\n",
       " 'PPPGO',\n",
       " 'PTPATi',\n",
       " 'PTRCt2pp',\n",
       " 'RNTR1c2',\n",
       " 'SEPHCHCS',\n",
       " 'SERt2rpp',\n",
       " 'SHCHCS3',\n",
       " 'SUCBZL',\n",
       " 'TARTD',\n",
       " 'TARTRt7pp',\n",
       " 'THMabcpp',\n",
       " 'THRD',\n",
       " 'TMDK1',\n",
       " 'TMK',\n",
       " 'UDCPDP',\n",
       " 'UPP3S',\n",
       " 'URDGLYCD',\n",
       " 'VALt2rpp',\n",
       " 'ZN2tpp'}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gapfilled_imat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GIMME finished in 33.0 seconds\n"
     ]
    }
   ],
   "source": [
    "# GIMME\n",
    "start_time = time.time()\n",
    "\n",
    "iJO1366_gimme_result = gimme(iJO1366, cutoff=102, expression_profile=m9_aerobic_driven)\n",
    "\n",
    "duration = time.time() - start_time\n",
    "duration = round(duration)\n",
    "\n",
    "print('GIMME finished in ' + str(duration) + ' seconds')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "130\n",
      "Objective value: nan\n"
     ]
    }
   ],
   "source": [
    "# Integrate GIMME results\n",
    "current = 0\n",
    "remove = []\n",
    "for entry in iJO1366_gimme_result.data_frame['inconsistency_scores']:\n",
    "    if entry != 0.0:\n",
    "        remove.append(list(iJO1366_gimme_result.fluxes.index)[current])\n",
    "    current += 1\n",
    "\n",
    "iJO1366_gimme = copy.deepcopy(iJO1366)\n",
    "\n",
    "# Constrain fluxes to match output\n",
    "for rxn_id, flux in iJO1366_gimme_result.fluxes.items():\n",
    "    iJO1366_gimme.reactions.get_by_id(rxn_id).bounds = (flux, flux)\n",
    "    \n",
    "# Prune inactive reactions\n",
    "for rxn in remove:\n",
    "    iJO1366_gimme.reactions.get_by_id(rxn).remove_from_model(remove_orphans=True)\n",
    "iJO1366_gimme.reactions.get_by_id('DM_4crsol_c').remove_from_model(remove_orphans=True)\n",
    "print(len(remove))\n",
    "removed = 1\n",
    "while removed == 1:\n",
    "    removed = 0\n",
    "    for cpd in iJO1366_gimme.metabolites:\n",
    "        if len(cpd.reactions) == 0:\n",
    "            cpd.remove_from_model(); removed = 1\n",
    "    for rxn in iJO1366_gimme.reactions:\n",
    "        if len(rxn.metabolites) == 0: \n",
    "            rxn.remove_from_model(); removed = 1\n",
    "\n",
    "# Test for growth\n",
    "print('Objective value: ' + str(iJO1366_gimme.slim_optimize()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ABUTt2pp',\n",
       " 'ACACT2r',\n",
       " 'ACACT3r',\n",
       " 'ACACT4r',\n",
       " 'ACACT5r',\n",
       " 'ACACT6r',\n",
       " 'ACACT7r',\n",
       " 'ACACT8r',\n",
       " 'ADCL',\n",
       " 'ADCS',\n",
       " 'ADOCBLabcpp',\n",
       " 'AGPAT160',\n",
       " 'AGPAT161',\n",
       " 'AGPAT181',\n",
       " 'ALAGLUE',\n",
       " 'ALLTN',\n",
       " 'ALLTNt2rpp',\n",
       " 'ARGORNt7pp',\n",
       " 'ASNt2rpp',\n",
       " 'BMOGDS1',\n",
       " 'BMOGDS2',\n",
       " 'CAt6pp',\n",
       " 'CLt3_2pp',\n",
       " 'CPMPS',\n",
       " 'CPPPGO',\n",
       " 'CTECOAI7',\n",
       " 'CTECOAI8',\n",
       " 'CU2tpp',\n",
       " 'D_LACt2pp',\n",
       " 'DHFR',\n",
       " 'DHNAOT4',\n",
       " 'DHNPA2r',\n",
       " 'DPCOAK',\n",
       " 'DRPA',\n",
       " 'DTMPK',\n",
       " 'ECOAH1',\n",
       " 'ECOAH2',\n",
       " 'ECOAH3',\n",
       " 'ECOAH4',\n",
       " 'ECOAH5',\n",
       " 'ECOAH6',\n",
       " 'ECOAH7',\n",
       " 'ECOAH8',\n",
       " 'FACOAE160',\n",
       " 'FACOAE161',\n",
       " 'FACOAE181',\n",
       " 'FCLT',\n",
       " 'FE2tpp',\n",
       " 'FEENTERabcpp',\n",
       " 'FESR',\n",
       " 'FLDR2',\n",
       " 'GAM6Pt6_2pp',\n",
       " 'GLYAT',\n",
       " 'GLYC3Pt6pp',\n",
       " 'GLYCLTt2rpp',\n",
       " 'GSNt2pp',\n",
       " 'GTHRDabcpp',\n",
       " 'HACD1',\n",
       " 'HACD2',\n",
       " 'HACD3',\n",
       " 'HACD4',\n",
       " 'HACD5',\n",
       " 'HACD6',\n",
       " 'HACD7',\n",
       " 'HACD8',\n",
       " 'HPPK2',\n",
       " 'HYD1pp',\n",
       " 'I2FE2SS',\n",
       " 'I2FE2SS2',\n",
       " 'ILEt2rpp',\n",
       " 'INDOLEt2rpp',\n",
       " 'IPDDI',\n",
       " 'LALDO2x',\n",
       " 'LEUt2rpp',\n",
       " 'LIPAMPL',\n",
       " 'LIPATPT',\n",
       " 'MAN6Pt6_2pp',\n",
       " 'MECDPS',\n",
       " 'MEPCT',\n",
       " 'METabcpp',\n",
       " 'MGSA',\n",
       " 'MN2tpp',\n",
       " 'MOADSUx',\n",
       " 'MOCDS',\n",
       " 'MOGDS',\n",
       " 'MPTAT',\n",
       " 'MPTG',\n",
       " 'MPTG2',\n",
       " 'MPTS',\n",
       " 'MPTSS',\n",
       " 'MTHFR2',\n",
       " 'NADH16pp',\n",
       " 'NADK',\n",
       " 'NO3R1pp',\n",
       " 'NO3t7pp',\n",
       " 'OPHBDC',\n",
       " 'PFL',\n",
       " 'PGPP160',\n",
       " 'PGPP160pp',\n",
       " 'PGPP161',\n",
       " 'PGPP161pp',\n",
       " 'PGPP181',\n",
       " 'PGPP181pp',\n",
       " 'PGSA160',\n",
       " 'PGSA161',\n",
       " 'PGSA181',\n",
       " 'PNTOt4pp',\n",
       " 'PPPGO',\n",
       " 'PTPATi',\n",
       " 'PTRCORNt7pp',\n",
       " 'PTRCt2pp',\n",
       " 'R15BPK',\n",
       " 'SEPHCHCS',\n",
       " 'SHCHCS3',\n",
       " 'SUCBZL',\n",
       " 'TARTD',\n",
       " 'TARTRt7pp',\n",
       " 'THMabcpp',\n",
       " 'THRD',\n",
       " 'TMAOR1pp',\n",
       " 'TMDK1',\n",
       " 'TMK',\n",
       " 'TRPAS2',\n",
       " 'UDCPDP',\n",
       " 'UM4PCP',\n",
       " 'UPP3S',\n",
       " 'URAt2pp_copy2',\n",
       " 'URDGLYCD',\n",
       " 'VALt2rpp',\n",
       " 'ZN2tpp']"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "remove"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Additional test datasets\n",
    "# Gao, Y., Yurkovich, J. T., Seo, S. W., Kabimoldayev, I., Dräger, A., Chen, K., … Palsson, B. O. (2018). \n",
    "# Systematic discovery of uncharacterized transcription factors in Escherichia coli K-12 MG1655. \n",
    "# Nucleic Acids Research. https://doi.org/10.1093/nar/gky752\n",
    "\n",
    "mops_glc = {}\n",
    "with open('/home/mjenior/Desktop/Gao_et_al_2018/GSM3022135_wt_glc1.txt', 'r') as transcription:\n",
    "    header = transcription.readline()\n",
    "    for line in transcription:\n",
    "        line = line.split()\n",
    "        if len(line) < 2: continue\n",
    "        mops_glc[line[0]] = float(line[1])\n",
    "\n",
    "wt_ph5 = {}\n",
    "with open('/home/mjenior/Desktop/Gao_et_al_2018/GSM3108934_wt_ph5_1.txt', 'r') as transcription:\n",
    "    header = transcription.readline()\n",
    "    for line in transcription:\n",
    "        line = line.split()\n",
    "        if len(line) < 2: continue\n",
    "        wt_ph5[line[0]] = float(line[1])\n",
    "\n",
    "wt_ph8 = {}\n",
    "with open('/home/mjenior/Desktop/Gao_et_al_2018/GSM3108936_wt_ph8_1.txt', 'r') as transcription:\n",
    "    header = transcription.readline()\n",
    "    for line in transcription:\n",
    "        line = line.split()\n",
    "        if len(line) < 2: continue\n",
    "        wt_ph8[line[0]] = float(line[1])\n",
    "\n",
    "ydcI_ph5 = {}\n",
    "with open('/home/mjenior/Desktop/Gao_et_al_2018/GSM3108944_delydci_ph5_1.txt', 'r') as transcription:\n",
    "    header = transcription.readline()\n",
    "    for line in transcription:\n",
    "        line = line.split()\n",
    "        if len(line) < 2: continue\n",
    "        ydcI_ph5[line[0]] = float(line[1])\n",
    "\n",
    "ydcI_ph8 = {}\n",
    "with open('/home/mjenior/Desktop/Gao_et_al_2018/GSM3108946_delydci_ph8_1.txt', 'r') as transcription:\n",
    "    header = transcription.readline()\n",
    "    for line in transcription:\n",
    "        line = line.split()\n",
    "        if len(line) < 2: continue\n",
    "        ydcI_ph8[line[0]] = float(line[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analyzing the C. difficile 630 model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in transcript abundance table\n",
    "def read_transcription_all(transcript_table):\n",
    "    \n",
    "    cef = {}\n",
    "    clinda = {}\n",
    "    strep = {}\n",
    "    gnoto = {}\n",
    "    \n",
    "    with open(transcript_table, 'r') as transcripts:\n",
    "        firstline = transcripts.readline()\n",
    "        \n",
    "        for line in transcripts:\n",
    "            line = line.split(',')\n",
    "            \n",
    "            cef[str(line[0])] = float(line[1])\n",
    "            clinda[str(line[0])] = float(line[2])\n",
    "            strep[str(line[0])] = float(line[3])\n",
    "            gnoto[str(line[0])] = float(line[4])\n",
    "        \n",
    "    return cef, clinda, strep, gnoto\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in all transcription \n",
    "cef_dict, clinda_dict, strep_dict, gnoto_dict = read_transcription_all('data/transcript/cdf_transcription.sub.format.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "iCdJ794 = cobra.io.read_sbml_model('data/iCdJ794.sbml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Substrate demand calculations\n",
    "\n",
    "import numpy\n",
    "import pandas\n",
    "import operator\n",
    "from cobra.flux_analysis.parsimonious import *\n",
    "from cobra.flux_analysis.geometric import *\n",
    "\n",
    "# Calculate extracellular metabolite shadow prices\n",
    "def sampled_exchange_fluxes(model, flux_samples):\n",
    "    \n",
    "    exch_fluxes = {}\n",
    "    for rxn in model.reactions: \n",
    "        if 'EX_' not in rxn.id: continue\n",
    "        exch_fluxes[rxn.id] = []\n",
    "    \n",
    "    print('Collecting exchange fluxes...')\n",
    "    with model as m:\n",
    "        for index in range(0, len(flux_samples.index)):\n",
    "            for rxn in flux_samples.columns:\n",
    "                try:\n",
    "                    m.reactions.get_by_id(rxn).bounds = (list(flux_samples[rxn])[index], list(flux_samples[rxn])[index])\n",
    "                except:\n",
    "                    continue\n",
    "                    \n",
    "            solution = m.optimize()\n",
    "            for rxn, flux in solution.fluxes.iteritems():\n",
    "                if 'EX_' not in rxn: continue\n",
    "                exch_fluxes[rxn].append(flux)\n",
    "\n",
    "    print('Calculating ranges...')\n",
    "    summary_stats = {}\n",
    "    for rxn in exch_fluxes.keys():\n",
    "        substrate = model.reactions.get_by_any(rxn).metabolites[0].name\n",
    "        summary_stats[rxn] = [substrate, numpy.percentile(exch_fluxes[rxn], 25), numpy.median(exch_fluxes[rxn]), numpy.percentile(exch_fluxes[rxn], 75),]\n",
    "\n",
    "    ranking = []\n",
    "    for rxn in summary_stats.keys(): ranking.append([rxn] + summary_stats[rxn])\n",
    "    ranking = sorted(ranking, key=operator.itemgetter(3), reverse=True)\n",
    "    temp_dict = {}\n",
    "    for x in ranking: temp_dict[x[0]] = x[1:]\n",
    "    flux_df = pandas.DataFrame.from_dict(temp_dict, orient='index', columns=['Name', 'Q25', 'Median', 'Q75'])\n",
    "    \n",
    "    return flux_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cross-reference shadow price with metabolomics data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-5-d8f8d915704f>, line 79)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-5-d8f8d915704f>\"\u001b[0;36m, line \u001b[0;32m79\u001b[0m\n\u001b[0;31m    if shifts[rxn.id][0]\u001b[0m\n\u001b[0m                         ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "# Metabolomics\n",
    "\n",
    "# Read in metabolomics data and collect intensities groups\n",
    "def read_metabolomics(intensities_file, group1, group2):\n",
    "    \n",
    "    with open(intensities_file, 'r') as intensities:\n",
    "        \n",
    "        header = intensities.readline().split()\n",
    "        group1_idx = []\n",
    "        for index in group1:\n",
    "            group1_idx.append(group1.index(index))\n",
    "        group2_idx = []\n",
    "        for index in group2:\n",
    "            group2_idx.append(group2.index(index))\n",
    "        \n",
    "        group1_dict = {}\n",
    "        group2_dict = {}\n",
    "        for line in intensities:\n",
    "            group1_dict[line[0]] = [float(line[x]) for x in group1_idx]\n",
    "            group2_dict[line[0]] = [float(line[x]) for x in group2_idx]\n",
    "             \n",
    "    return group1_dict, group2_dict\n",
    "\n",
    "\n",
    "# Test direction of change and significant differences in metaboalite values\n",
    "def test_differences(dict1, dict2, cutoff=0.05):\n",
    "    \n",
    "    diff_dict = {}\n",
    "    for index in dict1.keys():\n",
    "        \n",
    "        median1 = median(dict1[index])\n",
    "        median2 = median(dict2[index])\n",
    "        if median1 > median2:\n",
    "            direction = 1\n",
    "        elif median1 < median2:\n",
    "            direction = -1\n",
    "        else:\n",
    "            direction = 0\n",
    "            \n",
    "        pval = round(list(scipy.stats.wilcoxon(x=dict1[index], y=dict2[index], zero_method='wilcox'))[1], 3)\n",
    "        if pval <= cutoff:\n",
    "            continue\n",
    "        else:    \n",
    "            diff_dict[index] = [direction, sig]\n",
    "    \n",
    "    return diff_dict\n",
    "\n",
    "\n",
    "# Identify required grwoth substrates\n",
    "def identify_requirements(model):\n",
    "    \n",
    "    with model as m:\n",
    "        solution = flux_variability_analysis(m)\n",
    "        \n",
    "        necessary = []\n",
    "        for index, row in solution.iterrows():\n",
    "            if 'EX_' not in index:\n",
    "                continue\n",
    "            elif row['minimum'] < 0.0 and row['maximum'] <= 0.0:\n",
    "                cpd = list(m.reactions.get_by_id(index).metabolites)[0].id\n",
    "                necessary.append(cpd)\n",
    "    \n",
    "    return(necessary)\n",
    "\n",
    "\n",
    "# Alter exchange fluxes based on metabolomic shifts\n",
    "def integrate_changes(model, shifts, required):\n",
    "    \n",
    "    new_model = copy.deepcopy(model)\n",
    "    for rxn in new_model.reactions:\n",
    "        if 'EX_' in rxn.id:\n",
    "            \n",
    "            cpd = list(rxn.metabolites)[0].id\n",
    "            if cpd in required:\n",
    "                continue\n",
    "            else:\n",
    "                \n",
    "                #integrate data here, just remove the reaction i guess...\n",
    "                if shifts[rxn.id][0] \n",
    "                    rxn.remove_from_model()\n",
    "                \n",
    "                \n",
    "        else:\n",
    "            continue\n",
    "                      \n",
    "    return new_model \n",
    "\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in metabolomic results\n",
    "untreated_mock = {}\n",
    "cef_630 = {}\n",
    "cef_mock = {}\n",
    "clinda_630 = {}\n",
    "clinda_mock = {}\n",
    "strep_630 = {}\n",
    "strep_mock = {}\n",
    "gnoto_630 = {}\n",
    "gnoto_mock = {}\n",
    "\n",
    "with open('data/metabolome/scaled_intensities.tsv', 'r') as metabolome:\n",
    "    \n",
    "    firstLine = metabolome.readline()\n",
    "    \n",
    "    for line in metabolome:\n",
    "        line = line.split()\n",
    "        \n",
    "        untreated_mock[line[0]] = numpy.median([float(x) for x in line[5:14]])\n",
    "        cef_630[line[0]] = numpy.median([float(x) for x in line[14:23]])\n",
    "        cef_mock[line[0]] = numpy.median([float(x) for x in line[23:32]])\n",
    "        clinda_630[line[0]] = numpy.median([float(x) for x in line[32:41]])\n",
    "        clinda_mock[line[0]] = numpy.median([float(x) for x in line[41:50]])\n",
    "        strep_630[line[0]] = numpy.median([float(x) for x in line[50:59]])\n",
    "        strep_mock[line[0]] = numpy.median([float(x) for x in line[59:68]])\n",
    "        gnoto_630[line[0]] = numpy.median([float(x) for x in line[68:77]])\n",
    "        gnoto_mock[line[0]] = numpy.median([float(x) for x in line[77:86]])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculates change in concentration of a metabolite across metabolomes\n",
    "def compare_concentration(metabolome1, metabolome2, metabolite):\n",
    "    \n",
    "    conc1 = 10 ** metabolome1[metabolite]\n",
    "    conc2 = 10 ** metabolome2[metabolite]\n",
    "    change = conc2 - conc1\n",
    "    \n",
    "    if change == 0.0:\n",
    "        change = change\n",
    "    elif change < 0.0:\n",
    "        change = -numpy.log10(abs(change))\n",
    "    else:\n",
    "        change = numpy.log10(change)\n",
    "\n",
    "    print(metabolite + ': ' + str(change))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fructose: 1.2869729381320378\n",
      "N-acetyl-beta-glucosaminylamine: -0.3669198398437978\n"
     ]
    }
   ],
   "source": [
    "# Cefoperazone\n",
    "compare_concentration(cef_mock, cef_630, 'fructose')\n",
    "compare_concentration(cef_mock, cef_630, 'N-acetyl-beta-glucosaminylamine')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fructose: 2.0225923028374746\n"
     ]
    }
   ],
   "source": [
    "# Clindamycin\n",
    "compare_concentration(clinda_mock, clinda_630, 'fructose')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fructose: 1.411164101349768\n"
     ]
    }
   ],
   "source": [
    "# Streptomycin\n",
    "compare_concentration(strep_mock, strep_630, 'fructose')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fructose: 1.411164101349768\n",
      "proline: -2.2705935392452883\n"
     ]
    }
   ],
   "source": [
    "# Gnotobiotic\n",
    "compare_concentration(strep_mock, strep_630, 'fructose')\n",
    "compare_concentration(strep_mock, strep_630, 'proline')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:anaconda2]",
   "language": "python",
   "name": "conda-env-anaconda2-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
